{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* &nbsp;\n",
    "\t* [imports](#imports)\n",
    "\t* [simple functions](#simple-functions)\n",
    "* [Load data](#Load-data)\n",
    "\t* [setting paths](#setting-paths)\n",
    "\t* [parsed content and raw questions and descriptions](#parsed-content-and-raw-questions-and-descriptions)\n",
    "\t* [localization and recognition](#localization-and-recognition)\n",
    "\t* [building spellings and grammar](#building-spellings-and-grammar)\n",
    "* [Clean and prepare data](#Clean-and-prepare-data)\n",
    "\t* [extract media links](#extract-media-links)\n",
    "\t* [remove non-conforming content](#remove-non-conforming-content)\n",
    "\t\t* [code](#code)\n",
    "\t\t* [run](#run)\n",
    "\t* [remove recognition and localization errors](#remove-recognition-and-localization-errors)\n",
    "* [Add image annotations](#Add-image-annotations)\n",
    "\t* [localization](#localization)\n",
    "\t* [recognition](#recognition)\n",
    "\t\t* [code](#code)\n",
    "\t\t* [run](#run)\n",
    "\t\t* [hide](#hide)\n",
    "* [Integrate diagram questions and descriptions](#Integrate-diagram-questions-and-descriptions)\n",
    "\t* [match diagram topics to lessons](#match-diagram-topics-to-lessons)\n",
    "\t\t* [code](#code)\n",
    "\t\t* [run](#run)\n",
    "\t\t* [hide](#hide)\n",
    "\t* [merge questions](#merge-questions)\n",
    "\t\t* [code](#code)\n",
    "\t\t* [run](#run)\n",
    "\t\t* [hide](#hide)\n",
    "\t* [merge descriptions](#merge-descriptions)\n",
    "\t\t* [hide](#hide)\n",
    "\t* [Apply spelling and grammar fixes](#Apply-spelling-and-grammar-fixes)\n",
    "\t\t* [code](#code)\n",
    "\t\t* [run](#run)\n",
    "\t\t* [hide](#hide)\n",
    "* [Topic key collisions](#Topic-key-collisions)\n",
    "* [Refinements to make](#Refinements-to-make)\n",
    "* [End](#End)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pylab as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext base16_mplrc\n",
    "# %base16_mplrc light solarized\n",
    "%base16_mplrc dark solarized\n",
    "plt.rcParams['grid.linewidth'] = 0\n",
    "plt.rcParams['figure.figsize'] = (16.0, 10.0)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from scipy.stats.mstats import mode\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import pprint\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import io\n",
    "import sys\n",
    "import os\n",
    "from binascii import b2a_hex\n",
    "import base64\n",
    "from wand.image import Image as WImage\n",
    "from IPython.display import display\n",
    "from IPython.core.display import HTML\n",
    "import PIL.Image as Image\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import language_check\n",
    "import enchant\n",
    "import difflib\n",
    "import diff_match_patch\n",
    "import fuzzywuzzy.fuzz as fuzz\n",
    "import re\n",
    "import jsonschema\n",
    "from pdfextraction.ck12_new_schema import ck12_schema as new_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## simple functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def write_file(filename, data_dict, output_dir='output_data_from_nbs'):\n",
    "    with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "        json.dump(data_dict, f, indent=4, sort_keys=True)\n",
    "        \n",
    "def get_img_n(image_name):\n",
    "    return [re.findall(\"[0-9]+\", image_name)][0][0]\n",
    "\n",
    "def clean_list(dir_path):\n",
    "    hidden_removed = filter(lambda f: not f.startswith('.'), os.listdir(dir_path))\n",
    "    return [topic.replace('_diagram', '') for topic in hidden_removed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load last_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# with open('build_v5.pkl', 'r') as f:\n",
    "#     latest_checkpoint = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "output_dir = 'output_data_from_nbs/'\n",
    "raw_data_dir = '../spare5_produced_data/data/'\n",
    "raw_dq_file = 'ai2_testquestions_20161005.csv'\n",
    "s5_raw_decriptions = 'ai2_diagramdescriptions_20161018.csv'\n",
    "ai2_raw_decriptions = 'our_description.csv'\n",
    "glossary_path = os.path.join(output_dir, 'flexbook_glossary.pkl')\n",
    "\n",
    "turk_proc_dir = '/Users/schwenk/wrk/stb/diagram_questions/turk_processing/'\n",
    "metadata_dir = turk_proc_dir + 'store_hit_results_metadata/'\n",
    "lc_results_dir = 'loc_group_3'\n",
    "box_loc_joined = 'loc_annotations'\n",
    "recog_results_dir = 'group_latest_combined'\n",
    "\n",
    "box_choices_1_dir = 'final_text_boxes_fixed'\n",
    "box_choices_2_dir = 'final_text_boxes_pass_2'\n",
    "none_agree = 'no_turkers_agree_lookup.pkl'\n",
    "two_agree_lookup = 'two_turkers_agree_lookup.pkl'\n",
    "all_agree_lookup = 'user_diag_loopkup.pkl'\n",
    "\n",
    "recog_performed = '/Users/schwenk/wrk/stb/diagram_questions/turk_processing/final_diagrams/'\n",
    "all_dir = '/Users/schwenk/wrk/stb/ai2-vision-textbook-dataset/diagrams/tqa_diagrams_v0.9/'\n",
    "pruned_dir = '/Users/schwenk/wrk/stb/ai2-vision-textbook-dataset/diagrams/dataset_Sep_27/tqa_diagrams_v0.9_question_images/'\n",
    "description_dir = '/Users/schwenk/wrk/stb/spare5_produced_data/tqa_diagrams_v0.9_inbook/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## parsed content and raw questions and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# load complete text v 3.5, raw diagram questions and descriptions\n",
    "# now ck12_dataset_text_only_beta_v5_build.json\n",
    "with open(output_dir + 'ck12_dataset_text_only_beta_v5_build.json', 'r') as f:\n",
    "    ck12_combined_dataset_raw = json.load(f)\n",
    "with open(output_dir + 'ck12_flexbook_only_beta_v3.json', 'r') as f:\n",
    "    flexbook_ds = json.load(f)\n",
    "with open(output_dir + 'ck12_lessons_only_beta_v3.json', 'r') as f:\n",
    "    lessons_ds = json.load(f)\n",
    "\n",
    "# loading questions\n",
    "desc_df = pd.read_csv(raw_data_dir + s5_raw_decriptions, encoding='latin-1')\n",
    "desc_df['diagram'] = desc_df['reference_id'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "ai2_raw_decriptions_df = pd.read_csv(raw_data_dir + ai2_raw_decriptions, encoding='latin-1')\n",
    "ai2_written_df_completed = ai2_raw_decriptions_df[['Topic', 'Image Path', 'Description']]\n",
    "ai2_written_df_completed['diagram'] = ai2_written_df_completed['Image Path'].apply(lambda x: x.split('/')[-1])\n",
    "ai2_written_df_completed['topic'] = ai2_written_df_completed['Topic']\n",
    "del  ai2_written_df_completed['Topic']\n",
    "\n",
    "#loading questions\n",
    "# q_col = '03_write_question'\n",
    "# r_ans_col = '04_write_right_answer'\n",
    "# w_ans_col = '05_write_wrong_answers'\n",
    "# data_cols = [q_col, r_ans_col, w_ans_col]\n",
    "# raw_dq_df = pd.read_csv(raw_data_dir + raw_dq_file, encoding='latin-1')\n",
    "# dr_proc_df = raw_dq_df.copy()\n",
    "# dr_proc_df['wac_list'] = dr_proc_df[w_ans_col].apply(lambda x: json.loads(x))\n",
    "# dr_proc_df['diagram'] = dr_proc_df['reference_id'].apply(lambda x: x.split('/')[-1])\n",
    "# dr_proc_df['topic'] = dr_proc_df['reference_id'].apply(lambda x: x.split('/')[-1].rsplit('_', maxsplit=1)[0])\n",
    "\n",
    "dr_proc_df = pd.read_pickle('complete_s5_dq.pkl')\n",
    "dr_proc_df['diagram'] = dr_proc_df['reference_id'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "\n",
    "with open('../diagram_questions/topic_match_terms.json', 'r') as f:\n",
    "    topic_term_match = json.load(f)    \n",
    "\n",
    "with open(glossary_path, 'rb') as f:\n",
    "    flexbook_glossary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### localization and recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "loc_res_df = pd.read_pickle(os.path.join(metadata_dir, lc_results_dir, 'complete_df.pkl'))\n",
    "recog_res_df = pd.read_pickle(os.path.join(metadata_dir, recog_results_dir, 'recog_df.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## building spellings and grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# loading spelling defs\n",
    "with open(output_dir + 'ck_12_vocab_words.pkl', 'rb') as f:\n",
    "    ck_12_vocab = set(pickle.load(f))\n",
    "with open(output_dir + 'ck_12_all_words.pkl', 'rb') as f:\n",
    "    ck_12_corp = set(pickle.load(f))\n",
    "    \n",
    "with open(output_dir + 'spellings_to_rev.txt', 'r') as f:\n",
    "    whitelisted_words = f.read().split('\\n')[:-1]    \n",
    "with open(output_dir + './desc_spellings_to_rev.txt', 'r') as f:\n",
    "    whitelisted_words += f.read().split('\\n')[:-1]\n",
    "with open(output_dir + './ck_12_spelling_rev.txt', 'r') as f:\n",
    "    whitelisted_words += f.read().split('\\n')[:-1]\n",
    "with open('diagram_rec_corp.pkl', 'rb') as f:\n",
    "    diagram_rec_corpus = pickle.load(f)\n",
    "    \n",
    "ck_12_corp.update(ck_12_vocab)\n",
    "ck_12_corp.update(whitelisted_words)\n",
    "ck_12_corp.update(diagram_rec_corpus)\n",
    "\n",
    "# build spelling dict updated with words from science corpus\n",
    "edict = enchant.Dict(\"en_US\")\n",
    "anglo_edict = enchant.Dict(\"en_UK\")\n",
    "cached_sw = stopwords.words(\"english\") + list(string.punctuation)\n",
    "for word in ck_12_corp:\n",
    "    if word.isalpha() and len(word) > 3:\n",
    "        edict.add(word)\n",
    "        \n",
    "# grammaer checker\n",
    "gram_checker = language_check.LanguageTool('en-US')\n",
    "gram_checker.disabled = set(['SENT_START_CONJUNCTIVE_LINKING_ADVERB_COMMA', 'POSSESSIVE_APOSTROPHE', 'A_PLURAL'])\n",
    "gram_checker.disable_spellchecking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Clean and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## extract media links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ck12_combined_dataset = deepcopy(ck12_combined_dataset_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pat_str = \"(?:https?:\\/\\/(?:www\\.).*?\\s)\"\n",
    "web_link_patern=re.compile(pat_str)\n",
    "\n",
    "def clean_content_text(content_str, web_link_patern):\n",
    "    removed_links = web_link_patern.findall(content_str)\n",
    "    if not removed_links:\n",
    "        return '', ''\n",
    "    split_txt = web_link_patern.split(content_str)\n",
    "    cleaned_text = ' '.join([txt for txt in split_txt if txt])\n",
    "    return cleaned_text, [link.strip() for link in removed_links]\n",
    "\n",
    "def extract_links(complete_ds):\n",
    "    for subject, lessons in complete_ds.items():\n",
    "        for lesson_title, lesson in lessons.items():\n",
    "            for topic, content in lesson['topics'].items():\n",
    "                content_str = content['content']['text']\n",
    "                new_text, links = clean_content_text(content_str, web_link_patern)\n",
    "                content['content']['mediaLinks'] = []\n",
    "                if links:\n",
    "                    content['content']['text'] = new_text\n",
    "                    content['content']['mediaLinks'].extend(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "extract_links(ck12_combined_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## remove non-conforming content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### old code (nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def validate_schema(dataset_json, schema):\n",
    "    errors = []\n",
    "    try:\n",
    "        validator = jsonschema.Draft4Validator(schema)\n",
    "        for error in sorted(validator.iter_errors(dataset_json), key=lambda x: x.absolute_path[0]):\n",
    "            errors.append([error.message, list(error.absolute_path)[:4]])\n",
    "    except jsonschema.ValidationError as e:\n",
    "        errors.append(\"Error in schema --%s-\", e.message)\n",
    "    return errors\n",
    "\n",
    "def validate_dataset(dataset_json, scheme=schema):\n",
    "    for subject, flexbook in dataset_json.items():\n",
    "        schema_errors = validate_schema(flexbook, schema)\n",
    "        for lesson_name, lesson in flexbook.items():\n",
    "            ac_errors = check_ac_counts(lesson, subject, lesson_name)\n",
    "        all_errors = schema_errors + ac_errors\n",
    "        if not all_errors:\n",
    "            return 'all validation test passed'\n",
    "        else:\n",
    "            return all_errors\n",
    "\n",
    "def check_ac_counts(lesson_content, subject, lesson_name):\n",
    "    errors = []\n",
    "    for qid, question in lesson_content['questions']['nonDiagramQuestions'].items():\n",
    "        if question['type'] == 'Multiple Choice':\n",
    "            if len(question['answerChoices']) != 4:\n",
    "                errors.append([subject, lesson_name, qid + ' mc error'])\n",
    "        if question['type'] == 'True or False':\n",
    "            if len(question['answerChoices']) != 2:\n",
    "                errors.append([subject, lesson_name, qid + ' tf error'])\n",
    "    return errors\n",
    "\n",
    "def record_validation_errors(dataset):\n",
    "    qs_removed = []\n",
    "    for subject, flexbook in dataset.items():\n",
    "        validator = jsonschema.Draft4Validator(schema)\n",
    "        for error in sorted(validator.iter_errors(flexbook), key=lambda x: x.absolute_path[0]):\n",
    "            lesson, quest, question_class, q_number = list(error.absolute_path)[:4]\n",
    "            problem_q_section = dataset[subject][lesson][quest][question_class]\n",
    "            if q_number in problem_q_section.keys():\n",
    "#                 print(dataset[subject][lesson][quest][question_class].pop(q_number))\n",
    "                qs_removed.append(dataset[subject][lesson][quest][question_class].pop(q_number))\n",
    "    return qs_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### new code (flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "code_folding": [
     20
    ],
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def validate_schema(dataset_json, schema):\n",
    "    errors = []\n",
    "    try:\n",
    "        validator = jsonschema.Draft4Validator(schema)\n",
    "        for error in sorted(list(validator.iter_errors(dataset_json)), key=lambda x: x.absolute_schema_path[0]):\n",
    "            errors.append([error.message, list(error.absolute_path)[:4]])\n",
    "    except jsonschema.ValidationError as e:\n",
    "        errors.append(\"Error in schema --%s-\", e.message)\n",
    "    return errors\n",
    "\n",
    "def validate_dataset(dataset_json, scheme=schema):\n",
    "    schema_errors = validate_schema(dataset_json, schema)\n",
    "    for lesson_name, lesson in dataset_json.items():\n",
    "        ac_errors = check_ac_counts(lesson, subject, lesson_name)\n",
    "    all_errors = schema_errors + ac_errors\n",
    "    if not all_errors:\n",
    "        return 'all validation test passed'\n",
    "    else:\n",
    "        return all_errors\n",
    "\n",
    "def check_ac_counts(lesson_content, subject, lesson_name):\n",
    "    errors = []\n",
    "    for qid, question in lesson_content['questions']['nonDiagramQuestions'].items():\n",
    "        if question['type'] == 'Multiple Choice':\n",
    "            if len(question['answerChoices']) != 4:\n",
    "                errors.append([subject, lesson_name, qid + ' mc error'])\n",
    "        if question['type'] == 'True or False':\n",
    "            if len(question['answerChoices']) != 2:\n",
    "                errors.append([subject, lesson_name, qid + ' tf error'])\n",
    "    return errors\n",
    "\n",
    "def record_validation_errors(dataset):\n",
    "    qs_removed = []\n",
    "    validator = jsonschema.Draft4Validator(schema)\n",
    "    for error in sorted(validator.iter_errors(dataset), key=lambda x: x.absolute_path[0]):\n",
    "        print(error)\n",
    "#         lesson, quest, question_class, q_number = list(error.absolute_schema_path)[:4]\n",
    "#         problem_q_section = dataset[subject][lesson][quest][question_class]\n",
    "#             if q_number in problem_q_section.keys():\n",
    "#                 print(dataset[subject][lesson][quest][question_class].pop(q_number))\n",
    "#                 qs_removed.append(dataset[subject][lesson][quest][question_class].pop(q_number))\n",
    "    return qs_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['adjunctTopics', 'hidden', 'topics', 'lessonName', 'questions', 'globalID', 'instructionalDiagrams'])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flat_ds[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "validator = jsonschema.Draft4Validator(schema)\n",
    "ert = list(validator.iter_errors(test_flat_ds))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# record_validation_errors(test_flat_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "validator = jsonschema.Draft4Validator(schema)\n",
    "for error in sorted(validator.iter_errors(flexbook), key=lambda x: x.absolute_path[0]):\n",
    "    print error.message\n",
    "    print error.absolute_path\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_flat_ds = complete_flat_ds[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test_flat_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# validate_dataset(test_flat_ds, new_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# validate_schema(test_flat_ds, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pprint.pprint(new_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "qs_rem = record_validation_errors(ck12_combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qs_rem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## remove recognition and localization errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "diagram_image_names = clean_list(recog_performed)\n",
    "\n",
    "rec_files = glob.glob(all_dir + '*/*')\n",
    "more_paths = glob.glob(all_dir + '*/*')\n",
    "pruned_paths = glob.glob(pruned_dir + '*/*')\n",
    "more_files = [fp.split('/')[-1] for fp in more_paths]\n",
    "pruned_files = [fp.split('/')[-1] for fp in pruned_paths]\n",
    "desc_paths = glob.glob(description_dir + '*/*')\n",
    "desc_files = [fp.split('/')[-1] for fp in desc_paths]\n",
    "\n",
    "\n",
    "pruned_nums = set([get_img_n(name) for name in pruned_files])\n",
    "all_nums = set([get_img_n(name) for name in more_files])\n",
    "rec_nums = set([get_img_n(name) for name in diagram_image_names])\n",
    "desc_nums = set([get_img_n(name) for name in desc_files])\n",
    "\n",
    "removed_images = all_nums.difference(pruned_nums.union(desc_nums))\n",
    "\n",
    "removed_image_names = []\n",
    "for img_n in removed_images:\n",
    "    for image_name in more_files:\n",
    "        if img_n == get_img_n(image_name):\n",
    "            removed_image_names.append(image_name)\n",
    "\n",
    "name_change_lookup = {}\n",
    "for image_name in more_files:\n",
    "    img_n = get_img_n(image_name)\n",
    "    for newer_name in pruned_files:\n",
    "        if img_n == get_img_n(newer_name) and newer_name != image_name:\n",
    "            name_change_lookup[image_name] = newer_name\n",
    "\n",
    "removed_image_names = sorted(removed_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "blacklisted_topics = ['periodic_table', 'em_spectrum', 'hydrocarbons', 'geologic_time'] + ['lewis_dot_idapgrams', 'circuits']  # correct this mispelling in future round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(removed_image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Add image annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagram</th>\n",
       "      <th>rectangle</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>assignment_id</th>\n",
       "      <th>worker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parts_cell_1182.png</td>\n",
       "      <td>[[283, 192], [447, 238]]</td>\n",
       "      <td>3SA4EMRVJV39U1MGLCYP6KPFULH0PX</td>\n",
       "      <td>3BDCF01OGXVJNV1XRULS5F5Z4B6LYG</td>\n",
       "      <td>A1017VP86SLXRB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               diagram                 rectangle  \\\n",
       "0  parts_cell_1182.png  [[283, 192], [447, 238]]   \n",
       "\n",
       "                           hit_id                   assignment_id  \\\n",
       "0  3SA4EMRVJV39U1MGLCYP6KPFULH0PX  3BDCF01OGXVJNV1XRULS5F5Z4B6LYG   \n",
       "\n",
       "        worker_id  \n",
       "0  A1017VP86SLXRB  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_res_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_anno = clean_list(os.path.join(turk_proc_dir, box_loc_joined))\n",
    "loc_anno_images = [fig.split('.json')[0]  for fig in loc_anno]\n",
    "keep_figures = [fig for fig in loc_anno_images if fig not in removed_image_names]\n",
    "\n",
    "loc_box_path = os.path.join(turk_proc_dir, box_loc_joined)\n",
    "\n",
    "diag_loc_annotations = {}\n",
    "for diagram_name in keep_figures:\n",
    "    anno_file_path = os.path.join(loc_box_path, diagram_name + '.json')\n",
    "    if not os.path.exists(anno_file_path):\n",
    "        diagram_name = diagram_name.replace('optics_rays', 'optics_ray_diagrams')\n",
    "        anno_file_path = os.path.join(loc_box_path, diagram_name  + '.json')\n",
    "    with open(anno_file_path, 'r') as f:\n",
    "        diag_loc_annotations[diagram_name] = json.load(f)\n",
    "\n",
    "combined_master_file_list = pruned_files + desc_files\n",
    "combined_master_file_list_whitelisted = [file for file in combined_master_file_list if file in keep_figures]\n",
    "files_still_needing_localisation = sorted(list(set(combined_master_file_list).difference(set(diag_loc_annotations))))\n",
    "len(files_still_needing_localisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def most_common_strict(image_response):\n",
    "    \"\"\"\n",
    "    returns the consensus response of the three raw response strings for a given image\n",
    "    \"\"\"\n",
    "    most_common = image_response[1]['raw_text'].mode()\n",
    "    if most_common.empty:\n",
    "        most_common = 'nonconsensus'\n",
    "        noncon.append(image_response[1]['raw_text'])\n",
    "    else:\n",
    "        most_common = most_common.values[0]\n",
    "    return most_common\n",
    "\n",
    "def most_common_lax(image_response, strings_denoting_missing_image=[]):\n",
    "    \"\"\"\n",
    "    returns the consensus response after stripping white space and converting the reponses to lower case\n",
    "    \"\"\"\n",
    "    simple_sanitizer = lambda x : x.lower().strip().lstrip()\n",
    "    ind_responses = image_response[1]['raw_text'].values\n",
    "    probobly_blanks = [response for response in ind_responses if response in strings_denoting_missing_image]\n",
    "    if probobly_blanks:\n",
    "        return 'skip'\n",
    "    most_common = image_response[1]['raw_text'].apply(simple_sanitizer).mode()\n",
    "    if most_common.empty:\n",
    "        most_common = 'no consensus'\n",
    "        noncon[image_response[0][0]].extend(image_response[1]['raw_text'])\n",
    "    else:\n",
    "        most_common = most_common.values[0]\n",
    "    return most_common\n",
    "\n",
    "def find_transcriptions_matches(batch_results_df, response_matcher):\n",
    "    \"\"\"\n",
    "    returns a pandas series with the consunsus response for each image\n",
    "    \"\"\"\n",
    "    agreed_responses = pd.DataFrame()\n",
    "    for image_response in batch_results_df.groupby(['diagram', 'box_diag_idx']):\n",
    "        diagram_and_idx = image_response[0]\n",
    "        most_common = response_matcher(image_response, strings_denoting_missing_image=[])\n",
    "        if most_common == 'skip':\n",
    "            continue\n",
    "        this_row = pd.DataFrame(list(diagram_and_idx) + [most_common, image_response[1]['rectangle'].iloc[0], image_response[1]['assignment_id'].iloc[0]]).T\n",
    "        agreed_responses = pd.concat([agreed_responses, this_row])\n",
    "        # The reindex below is needed to match the original df index after the groupby operation\n",
    "    agreed_responses.columns = ['diagram', 'box_diag_idx', 'consensus_res', 'rectangle', 'assignment_id']\n",
    "    return agreed_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2190"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recog_performed_on = set(pd.unique(recog_res_df['diagram']).tolist())\n",
    "len(recog_performed_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "files_still_needing_recognition = sorted(list(set(pruned_files).difference(set(recog_performed_on))))\n",
    "print(len(files_still_needing_recognition))\n",
    "file_with_loc_no_recog = set(files_still_needing_recognition).difference(files_still_needing_localisation)\n",
    "print(len(file_with_loc_no_recog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "noncon = defaultdict(list)\n",
    "transcription_results_lax = find_transcriptions_matches(recog_res_df, most_common_lax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "noncon_entries = [entries for entries in noncon.values()]\n",
    "flattened_noncon = [item for sublist in noncon_entries for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "curated_no_image_strings = set(['*no image showing*', '', ' ', 'NA', '?', 'na', '0', 'No image found', 'blank', 'Nothing showing', \"where is the images , i can't see anything\", 'NO IMAGE', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "non_blank_no_consensus = {d_name: rec_res for d_name, rec_res in noncon.items() if not curated_no_image_strings.intersection(set(rec_res))}\n",
    "blank_no_consensus = {d_name: rec_res for d_name, rec_res in noncon.items() if curated_no_image_strings.intersection(set(rec_res))}\n",
    "print(len(non_blank_no_consensus))\n",
    "print(len(blank_no_consensus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "flattened_noncon_no_blank = [item for sublist in non_blank_no_consensus.values() for item in sublist]\n",
    "build_diagram_rec_corpus  = [words.split() for words in transcription_results_lax['consensus_res'].values.tolist()]\n",
    "diagram_rec_corpus = set([item.lower().strip() for sublist in build_diagram_rec_corpus for item in sublist if item.isalpha() and len(item) > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# transcription_results_lax.to_pickle('recog_proc_checkpoint.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# with open('diagram_rec_corp.pkl', 'wb') as f:\n",
    "#     pickle.dump(diagram_rec_corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# strings_denoting_missing_image = list(pd.Series(flattened_noncon).value_counts()[:20].index)\n",
    "# Image.open('../ai2-vision-textbook-dataset/diagrams/turk_data/optics_ray_diagrams_9170.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4073"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diagram_rec_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate diagram questions and descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## match diagram topics to lessons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "first need to match diagram topics to flexbook lessons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def make_topic_matches(topic_list, combined_topics):\n",
    "    topic_matches = {}\n",
    "    for diagram_topic in topic_list:\n",
    "        topic_matches[diagram_topic] = []\n",
    "        for terms in topic_term_match[diagram_topic]:\n",
    "            lev_dist_threshed = [topic for topic in combined_topics.keys() if fuzz.ratio(topic, terms) > 85]\n",
    "            topic_matches[diagram_topic] += lev_dist_threshed\n",
    "        if not topic_matches[diagram_topic]:\n",
    "                for terms in topic_term_match[diagram_topic]:\n",
    "                    lev_dist_threshed = [topic for topic in combined_topics.keys() if fuzz.token_set_ratio(topic, terms) > 80]\n",
    "                    topic_matches[diagram_topic] += lev_dist_threshed\n",
    "    return topic_matches\n",
    "\n",
    "def make_lesson_matches(ck12_dataset, diagram_topic_name, topic_matches):\n",
    "    lesson_matches = defaultdict(list)\n",
    "    lessons_seen = set()\n",
    "    content_topics =  topic_matches[diagram_topic_name]\n",
    "    for topic in sorted(content_topics):\n",
    "        associated_lesson =combined_topics[topic]['lesson']\n",
    "        if associated_lesson not in lessons_seen:\n",
    "            lessons_seen.add(associated_lesson)\n",
    "            lesson_matches[diagram_topic_name].append(associated_lesson)\n",
    "    return dict(lesson_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The pruned directory is the tqa 0.91 set assmbled by Ani on Sept 27th. It should be treated as definitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "diagram_topic_list = clean_list(pruned_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "es_lesson_names = [item for sublist in [val['topics'].keys() for val in ck12_combined_dataset['earth-science'].values()] for item in sublist]\n",
    "ps_lesson_names = [item for sublist in [val['topics'].keys() for val in ck12_combined_dataset['physical-science'].values()] for item in sublist]\n",
    "ls_lesson_names = [item for sublist in [val['topics'].keys() for val in ck12_combined_dataset['life-science'].values()] for item in sublist]\n",
    "\n",
    "combined_lessons = es_lesson_names + ps_lesson_names + ls_lesson_names\n",
    "topic_series = pd.Series(combined_lessons).value_counts()\n",
    "# the 17 here found by inspection- any \"topic\" appearing many times is something general like review, vocab, etc\n",
    "topics_to_remove = list(topic_series[:17].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "combined_topics = defaultdict(dict)\n",
    "for subject, book in ck12_combined_dataset.items():\n",
    "    for lesson, material in book.items():\n",
    "        for topic, text in material['topics'].items():\n",
    "            if topic in topics_to_remove:\n",
    "                continue\n",
    "            combined_topics[topic.lower()]['lesson'] = lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "topic_matches = make_topic_matches(diagram_topic_list, combined_topics)\n",
    "missing= []\n",
    "for k, v in topic_matches.items():\n",
    "    if not v:\n",
    "        missing.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "matching_lessons = {}\n",
    "for topic in diagram_topic_list:\n",
    "    matched_lessons = make_lesson_matches(ck12_combined_dataset, topic, topic_matches)\n",
    "    matching_lessons.update(matched_lessons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diagram_lesson_lookup = {}\n",
    "for d_topic, lessons in matching_lessons.items():\n",
    "    diagram_lesson_lookup[d_topic] = sorted(lessons)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#manually correct name changes made since diagrams were assembled\n",
    "diagram_lesson_lookup['lewis_dot_diagrams'] = diagram_lesson_lookup['lewis_dots']\n",
    "diagram_lesson_lookup['optics_ray_diagrams'] = diagram_lesson_lookup['optics_rays']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "lessons_seen = []\n",
    "dupe_lessons = []\n",
    "for k, v in diagram_lesson_lookup.items():\n",
    "    if v not in lessons_seen:\n",
    "        lessons_seen.append(v)\n",
    "    else:\n",
    "        dupe_lessons.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dupe_topics = defaultdict(list)\n",
    "for k, v in diagram_lesson_lookup.items():\n",
    "    if v in dupe_lessons:\n",
    "        dupe_topics[v].append(k)\n",
    "# dupe_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acid_rain_formation\n",
      "['22.2 Effects of Air Pollution']\n",
      "\n",
      "aquifers\n",
      "['13.3 Groundwater']\n",
      "\n",
      "atomic_mass_number\n",
      "['5.1 Inside the Atom', 'atomic number', 'matter mass and volume']\n",
      "\n",
      "atomic_structure\n",
      "['5.1 Inside the Atom']\n",
      "\n",
      "biomes\n",
      "['climate zones and biomes']\n",
      "\n",
      "blastocyst\n",
      "['22.3 Reproduction and Life Stages']\n",
      "\n",
      "cell_division\n",
      "['5.1 Cell Division']\n",
      "\n",
      "cellular_respiration\n",
      "['9.4 Biochemical Reactions']\n",
      "\n",
      "chemical_bonding_covalent\n",
      "['7.3 Covalent Bonds']\n",
      "\n",
      "chemical_bonding_ionic\n",
      "['7.2 Ionic Bonds']\n",
      "\n",
      "circuits\n",
      "['23.3 Electric Circuits']\n",
      "\n",
      "continental_drift\n",
      "['6.2 Continental Drift']\n",
      "\n",
      "convection_of_air\n",
      "['18.2 Transfer of Thermal Energy']\n",
      "\n",
      "cycle_carbon\n",
      "['18.2 Cycles of Matter']\n",
      "\n",
      "cycle_nitrogen\n",
      "['18.2 Cycles of Matter']\n",
      "\n",
      "cycle_rock\n",
      "['4.1 Types of Rocks', 'rocks and processes of the rock cycle']\n",
      "\n",
      "cycle_water\n",
      "['24.2 Cycles of Matter']\n",
      "\n",
      "dna\n",
      "['nucleic acid classification']\n",
      "\n",
      "earth_day_night\n",
      "['rotation of earth']\n",
      "\n",
      "earth_eclipses\n",
      "['eclipses']\n",
      "\n",
      "earth_magnetic_field\n",
      "['24.2 Earth as a Magnet']\n",
      "\n",
      "earth_moon_phases\n",
      "['24.4 The Sun and the EarthMoon System']\n",
      "\n",
      "earth_parts\n",
      "['6.1 Inside Earth']\n",
      "\n",
      "earth_poles\n",
      "['revolutions of earth']\n",
      "\n",
      "electromagnetism\n",
      "['25.2 Using Electromagnetism']\n",
      "\n",
      "em_spectrum\n",
      "['21.3 The Electromagnetic Spectrum', '23.1 Telescopes', 'electromagnetic spectrum', 'radio waves']\n",
      "\n",
      "erosion\n",
      "['10.1 Erosion and Deposition by Flowing Water', '10.2 Erosion and Deposition by Waves', '10.3 Erosion and Deposition by Wind', '10.4 Erosion and Deposition by Glaciers', '19.1 Loss of Soil', 'avoiding soil loss', 'landforms from groundwater erosion and deposition', 'rocks and processes of the rock cycle', 'soil erosion']\n",
      "\n",
      "eukaryotic_cell_cycles\n",
      "['5.1 Cell Division']\n",
      "\n",
      "evaporation_and_sublimation\n",
      "['4.3 Changes of State']\n",
      "\n",
      "faults\n",
      "['faults']\n",
      "\n",
      "food_chains_webs\n",
      "['24.1 Flow of Energy']\n",
      "\n",
      "fossils\n",
      "['11.1 Fossils']\n",
      "\n",
      "fungi_reproduction\n",
      "['9.2 Fungi']\n",
      "\n",
      "geologic_time\n",
      "['7.4 History of Life on Earth']\n",
      "\n",
      "glaciers\n",
      "['10.4 Erosion and Deposition by Glaciers', 'glaciers']\n",
      "\n",
      "greenhouse_effect\n",
      "['greenhouse effect']\n",
      "\n",
      "hair_follicles\n",
      "['nails and hair']\n",
      "\n",
      "human_system_circulatory\n",
      "['18.1 Overview of the Cardiovascular System']\n",
      "\n",
      "human_system_digestive\n",
      "['17.3 The Digestive System']\n",
      "\n",
      "human_system_ear\n",
      "['20.2 The Senses']\n",
      "\n",
      "human_system_excretory\n",
      "['19.2 The Excretory System']\n",
      "\n",
      "human_system_eye\n",
      "['22.3 Vision']\n",
      "\n",
      "human_system_immune\n",
      "['21.4 Immune System Defenses']\n",
      "\n",
      "human_system_muscular\n",
      "['16.4 The Muscular System']\n",
      "\n",
      "human_system_nervous\n",
      "['20.1 The Nervous System', 'central nervous system', 'diseases of the nervous system', 'injuries of the nervous system', 'keeping the nervous system healthy', 'nervous system', 'peripheral nervous system']\n",
      "\n",
      "human_system_reproductory\n",
      "['22.1 Male Reproductive System', '22.2 Female Reproductive System', '22.4 Reproductive System Health', 'female reproductive system', 'male reproductive system', 'reproductive system health']\n",
      "\n",
      "human_system_respiratory\n",
      "['19.1 The Respiratory System', 'respiratory system organs']\n",
      "\n",
      "hydrocarbons\n",
      "['9.2 Hydrocarbons', 'combustion reactions', 'hydrocarbons', 'saturated hydrocarbons', 'unsaturated hydrocarbons']\n",
      "\n",
      "isotopes\n",
      "['5.1 Inside the Atom']\n",
      "\n",
      "layers_of_atmosphere\n",
      "['15.3 Layers of the Atmosphere']\n",
      "\n",
      "lewis_dots\n",
      "['7.1 Introduction to Chemical Bonds']\n",
      "\n",
      "life_cycles\n",
      "['12.4 Insects and Other Arthropods']\n",
      "\n",
      "muscle_fiber\n",
      "['16.4 The Muscular System', 'muscles and exercise']\n",
      "\n",
      "nuclear_energy\n",
      "['11.3 Nuclear Energy']\n",
      "\n",
      "ocean_currents\n",
      "['14.2 Ocean Movements']\n",
      "\n",
      "ocean_waves\n",
      "['14.2 Ocean Movements', '19.1 Characteristics of Waves', 'gamma rays', 'transverse wave']\n",
      "\n",
      "ocean_zones\n",
      "['14.1 Introduction to the Oceans']\n",
      "\n",
      "optics_lense_types\n",
      "['22.2 Optics']\n",
      "\n",
      "optics_rays\n",
      "['law of reflection']\n",
      "\n",
      "optics_reflection\n",
      "['law of reflection']\n",
      "\n",
      "optics_refraction\n",
      "['22.2 Optics']\n",
      "\n",
      "ozone_formation\n",
      "['22.1 Air Pollution']\n",
      "\n",
      "parts_cell\n",
      "['3.2 Cell Structures', '4.1 Transport', 'cell transport']\n",
      "\n",
      "parts_chordate_body\n",
      "['12.5 Echinoderms and Invertebrate Chordates', 'chordates']\n",
      "\n",
      "parts_fish\n",
      "['13.2 Fish']\n",
      "\n",
      "parts_flower\n",
      "['10.2 Evolution and Classification of Plants']\n",
      "\n",
      "parts_leaf\n",
      "['10.1 Introduction to Plants']\n",
      "\n",
      "parts_microscope\n",
      "['1.4 The Microscope', 'microscopes', 'optical instruments']\n",
      "\n",
      "parts_neuron\n",
      "['20.1 The Nervous System']\n",
      "\n",
      "parts_ocean_floor\n",
      "['14.3 The Ocean Floor']\n",
      "\n",
      "parts_plant\n",
      "['10.1 Introduction to Plants', '10.2 Evolution and Classification of Plants', '10.3 Plant Responses and Special Adaptations', '14.2 Mammals', '5.2 Nonrenewable Energy Resources', '5.3 Renewable Energy Resources', '6.2 Continental Drift', '9.1 Weathering', 'chemical weathering', 'electrical grid', 'fungi classification', 'nonvascular plants', 'plant characteristics', 'reproduction in seedless plants', 'seeds and seed dispersal', 'symbiotic relationships of fungi', 'types of marine organisms', 'vascular seedless plants']\n",
      "\n",
      "parts_seed\n",
      "['10.2 Evolution and Classification of Plants']\n",
      "\n",
      "parts_skeleton\n",
      "['16.3 The Skeletal System']\n",
      "\n",
      "parts_telescope\n",
      "['22.2 Optics', 'optical instruments']\n",
      "\n",
      "parts_worm\n",
      "['12.2 Flatworms and Roundworms', 'roundworms']\n",
      "\n",
      "periodic_table\n",
      "['6.1 How Elements Are Organized']\n",
      "\n",
      "phagocytosis\n",
      "['21.3 First Two Lines of Defense']\n",
      "\n",
      "photosynthesis\n",
      "['4.2 Photosynthesis']\n",
      "\n",
      "protozoa\n",
      "['9.1 Protists']\n",
      "\n",
      "radioactive_decay\n",
      "['11.3 Absolute Ages of Rocks']\n",
      "\n",
      "rain_shadow\n",
      "['17.1 Climate and Its Causes']\n",
      "\n",
      "seafloor_spreading\n",
      "['magnetic evidence for seafloor spreading']\n",
      "\n",
      "seasons\n",
      "['seasons']\n",
      "\n",
      "seismic_waves\n",
      "['6.1 Inside Earth']\n",
      "\n",
      "simple_machines\n",
      "['16.3 Simple Machines']\n",
      "\n",
      "skin_cross_section\n",
      "['16.2 The Integumentary System']\n",
      "\n",
      "soil_horizons\n",
      "['9.2 Soils', 'processes of the water cycle']\n",
      "\n",
      "solar_system\n",
      "['25.1 Introduction to the Solar System']\n",
      "\n",
      "state_change\n",
      "['changes of state']\n",
      "\n",
      "states_of_matter\n",
      "['4.1 Solids Liquids Gases and Plasmas', 'kinetic theory of matter', 'solutions', 'states of water']\n",
      "\n",
      "stratigraphy\n",
      "['11.2 Relative Ages of Rocks']\n",
      "\n",
      "sun_layers\n",
      "['24.3 The Sun']\n",
      "\n",
      "tectonic_plates\n",
      "['6.4 Theory of Plate Tectonics']\n",
      "\n",
      "tectonic_plates_motion\n",
      "['6.4 Theory of Plate Tectonics', 'venus']\n",
      "\n",
      "tides\n",
      "['14.2 Ocean Movements']\n",
      "\n",
      "types_cells\n",
      "['cell biology']\n",
      "\n",
      "types_clouds\n",
      "['clouds']\n",
      "\n",
      "types_leaves\n",
      "['10.1 Introduction to Plants']\n",
      "\n",
      "velocity_time_graphs\n",
      "['12.3 Acceleration']\n",
      "\n",
      "volcanoes\n",
      "['8.3 Types of Volcanoes']\n",
      "\n",
      "waves\n",
      "['19.2 Measuring Waves']\n",
      "\n",
      "waves_interactions_interference\n",
      "['19.3 Wave Interactions and Interference']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len(diagram_lesson_lookup.keys())\n",
    "\n",
    "len(set(diagram_lesson_lookup.values()))\n",
    "\n",
    "for k, v in sorted(matching_lessons.items()):\n",
    "    print(k)\n",
    "    print(sorted(v))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# pprint.pprint(dict(dupe_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dq_image_folder = 'diagram-question-images/'\n",
    "td_image_folder = 'diagram-teaching-images/'\n",
    "\n",
    "def make_question_entry(qdf_row):\n",
    "    ask = qdf_row[qdf_row.index == '03_write_question'].values[0]\n",
    "    answer = qdf_row[qdf_row.index == '04_write_right_answer'].values[0]\n",
    "    wrong_answers = qdf_row[qdf_row.index == 'wac_list'].values[0]\n",
    "    q_topic = qdf_row[qdf_row.index == 'lesson_assigned_to'].values[0]\n",
    "    image_uri = qdf_row[qdf_row.index == 's3_uri'].values[0]\n",
    "    image_name = qdf_row[qdf_row.index == 'diagram'].values[0]\n",
    "    \n",
    "    def make_answer_choices(answer_choices):\n",
    "        build_answer_choices = {}\n",
    "        letter_options = list('abcd')\n",
    "        random.shuffle(answer_choices)\n",
    "        for idx, answer_choice in enumerate(answer_choices):\n",
    "            answer_choice_dict = {\n",
    "                \"idStructural\": letter_options[idx] + '.',\n",
    "                \"rawText\": answer_choice,\n",
    "                \"processedText\": answer_choice\n",
    "            }\n",
    "            build_answer_choices[letter_options[idx]] = answer_choice_dict\n",
    "        return build_answer_choices\n",
    "    a_choices = make_answer_choices(wrong_answers + [answer])\n",
    "    single_q_dict = {\n",
    "        \"id\": 'q',\n",
    "        \"type\": \n",
    "            \"Diagram Multiple Choice\",\n",
    "        \"beingAsked\": {\n",
    "            \"rawText\": ask,\n",
    "            \"processedText\": ask.encode('ascii', 'ignore').decode('utf-8')\n",
    "        },\n",
    "        \"correctAnswer\": {\n",
    "            \"rawText\": answer,\n",
    "            \"processedText\": answer.encode('ascii', 'ignore').decode('utf-8')\n",
    "        },\n",
    "        \"answerChoices\": a_choices,\n",
    "        \"imageUri\": image_uri,\n",
    "        \"imageName\": image_name\n",
    "    }\n",
    "    build_questions[q_topic].append(single_q_dict)\n",
    "    \n",
    "    \n",
    "def refine_question_formats(raw_questions):\n",
    "    reformatted_dq_ds = {}\n",
    "    for topic, topic_questions in raw_questions.items():\n",
    "        reformatted_topic = {topic: {'questions': {'diagramQuestions': {}}}}\n",
    "        reformatted_questions = {}\n",
    "        for idx, question in enumerate(topic_questions):\n",
    "            question = deepcopy(question)\n",
    "            question['id'] += str(idx + 1).zfill(4)\n",
    "            reformatted_questions[question['id']] = question\n",
    "        reformatted_topic[topic]['questions']['diagramQuestions'] = reformatted_questions\n",
    "        reformatted_dq_ds.update(reformatted_topic)\n",
    "    return reformatted_dq_ds\n",
    "\n",
    "s3_base = 'https://s3.amazonaws.com/ai2-vision-textbook-dataset/diagrams/' + dq_image_folder\n",
    "s3_base_descriptions = 'https://s3.amazonaws.com/ai2-vision-textbook-dataset/diagrams/' + td_image_folder\n",
    "\n",
    "def make_image_link(old_url, s3_base=s3_base):\n",
    "    image_name = old_url.split('/')[-1]\n",
    "    new_url = s3_base + image_name\n",
    "    return new_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dr_proc_df['s3_uri'] = dr_proc_df['reference_id'].apply(make_image_link)\n",
    "dr_proc_df['lesson_assigned_to'] = dr_proc_df['topic'].apply(lambda x: diagram_lesson_lookup[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "build_questions = defaultdict(list)\n",
    "_ = dr_proc_df.apply(make_question_entry, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "refined_questions = refine_question_formats(build_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for subject, lessons in ck12_combined_dataset.items():\n",
    "    for l_name, lesson in lessons.items():\n",
    "        if l_name in refined_questions.keys():        \n",
    "            lesson['questions']['diagramQuestions'] = refined_questions[l_name]['questions']['diagramQuestions']\n",
    "        else:\n",
    "            lesson['questions']['diagramQuestions']  = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['diagramQuestions'])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_questions = dict(refine_question_formats(build_questions))\n",
    "\n",
    "refined_questions['10.4 Erosion and Deposition by Glaciers']['questions'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "refined_questions['10.4 Erosion and Deposition by Glaciers']\n",
    "\n",
    "len(ck12_combined_dataset['earth-science']['10.4 Erosion and Deposition by Glaciers']['questions']['diagramQuestions'])\n",
    "\n",
    "len(ck12_combined_dataset['earth-science']['10.4 Erosion and Deposition by Glaciers']['questions']['nonDiagramQuestions'])\n",
    "\n",
    "val_counts=dr_proc_df['lesson_assigned_to'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.1 Introduction to Plants                     1146\n",
       "24.1 Flow of Energy                             1006\n",
       "3.2 Cell Structures                              916\n",
       "12.4 Insects and Other Arthropods                719\n",
       "17.3 The Digestive System                        569\n",
       "6.1 Inside Earth                                 405\n",
       "20.1 The Nervous System                          337\n",
       "seasons                                          306\n",
       "19.1 The Respiratory System                      291\n",
       "10.2 Evolution and Classification of Plants      281\n",
       "24.4 The Sun and the EarthMoon System            278\n",
       "22.3 Vision                                      267\n",
       "8.3 Types of Volcanoes                           213\n",
       "25.1 Introduction to the Solar System            197\n",
       "11.3 Nuclear Energy                              192\n",
       "18.1 Overview of the Cardiovascular System       181\n",
       "4.2 Photosynthesis                               177\n",
       "14.2 Ocean Movements                             172\n",
       "22.1 Male Reproductive System                    165\n",
       "5.1 Inside the Atom                              164\n",
       "23.3 Electric Circuits                           163\n",
       "16.4 The Muscular System                         147\n",
       "9.1 Protists                                     145\n",
       "1.4 The Microscope                               136\n",
       "22.2 Optics                                      128\n",
       "24.2 Cycles of Matter                            120\n",
       "6.4 Theory of Plate Tectonics                    120\n",
       "5.1 Cell Division                                117\n",
       "19.2 The Excretory System                        111\n",
       "eclipses                                         111\n",
       "                                                ... \n",
       "17.1 Climate and Its Causes                       59\n",
       "revolutions of earth                              55\n",
       "14.1 Introduction to the Oceans                   54\n",
       "21.3 First Two Lines of Defense                   53\n",
       "15.3 Layers of the Atmosphere                     53\n",
       "22.3 Reproduction and Life Stages                 53\n",
       "7.4 History of Life on Earth                      50\n",
       "cell biology                                      49\n",
       "12.3 Acceleration                                 45\n",
       "7.3 Covalent Bonds                                45\n",
       "rotation of earth                                 44\n",
       "9.2 Hydrocarbons                                  44\n",
       "24.2 Earth as a Magnet                            43\n",
       "9.4 Biochemical Reactions                         41\n",
       "7.1 Introduction to Chemical Bonds                39\n",
       "10.1 Erosion and Deposition by Flowing Water      38\n",
       "9.2 Fungi                                         37\n",
       "21.3 The Electromagnetic Spectrum                 35\n",
       "14.3 The Ocean Floor                              35\n",
       "25.2 Using Electromagnetism                       34\n",
       "greenhouse effect                                 34\n",
       "18.2 Transfer of Thermal Energy                   33\n",
       "10.4 Erosion and Deposition by Glaciers           33\n",
       "11.1 Fossils                                      28\n",
       "19.3 Wave Interactions and Interference           26\n",
       "22.2 Effects of Air Pollution                     25\n",
       "magnetic evidence for seafloor spreading          25\n",
       "11.2 Relative Ages of Rocks                       24\n",
       "7.2 Ionic Bonds                                   21\n",
       "22.1 Air Pollution                                19\n",
       "Name: lesson_assigned_to, dtype: int64"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## merge descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def make_description_entry(qdf_row):\n",
    "    description = qdf_row[qdf_row.index == 'Description'].values[0]\n",
    "    q_topic = qdf_row[qdf_row.index == 'lesson_assigned_to'].values[0]\n",
    "    image_uri = qdf_row[qdf_row.index == 's3_uri'].values[0]\n",
    "    image_name = qdf_row[qdf_row.index == 'diagram'].values[0]\n",
    "    image_key = image_name.replace('.png', '')\n",
    "    single_desc_dict = {\n",
    "        \"imageUri\": image_uri,\n",
    "        \"imageName\": image_name,\n",
    "        \"rawText\": description,\n",
    "        \"processedText\": description.encode('ascii', 'ignore').decode('utf-8')\n",
    "        }\n",
    "    if image_key not in build_descriptions[q_topic].keys():\n",
    "        build_descriptions[q_topic].update({image_key: single_desc_dict})\n",
    "    # I've found the longest description is usually best\n",
    "    elif len(single_desc_dict['processedText']) > len(build_descriptions[q_topic][image_key]['processedText']):\n",
    "        build_descriptions[q_topic].update({image_key: single_desc_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "ai2_written_df_completed['lesson_assigned_to'] = ai2_written_df_completed['topic'].apply(lambda x: diagram_lesson_lookup[x])\n",
    "ai2_written_df_completed['s3_uri'] = ai2_written_df_completed['Image Path'].apply(make_image_link)\n",
    "ai2_written_df_completed = ai2_written_df_completed.dropna()\n",
    "\n",
    "desc_df['topic'] = desc_df['diagram'].apply(lambda x: x.rsplit('_', maxsplit=1)[0])\n",
    "desc_df['lesson_assigned_to'] = desc_df['topic'].apply(lambda x: diagram_lesson_lookup[x])\n",
    "desc_df['s3_uri'] = desc_df['reference_id'].apply(make_image_link)\n",
    "desc_df['Description'] = desc_df['01_write_description']             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "build_descriptions = defaultdict(dict)\n",
    "_ = desc_df.apply(make_description_entry, axis=1)\n",
    "_ = ai2_written_df_completed.apply(make_description_entry, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# this adds the descriptions to the combined dataset\n",
    "for subject, lessons in ck12_combined_dataset.items():\n",
    "    for l_name, lesson in lessons.items():\n",
    "        if l_name in build_descriptions.keys():\n",
    "            lesson['instructionalDiagrams'] = build_descriptions[l_name]\n",
    "        else:\n",
    "            lesson['instructionalDiagrams'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85,)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(desc_df['lesson_assigned_to']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['12.4 Insects and Other Arthropods', '14.3 The Ocean Floor', '16.3 Simple Machines', 'cell biology', '10.2 Evolution and Classification of Plants', '9.2 Hydrocarbons', '18.1 Overview of the Cardiovascular System', '15.3 Layers of the Atmosphere', 'climate zones and biomes', '19.2 The Excretory System', '5.1 Cell Division', '10.1 Introduction to Plants', 'faults', 'eclipses', '24.3 The Sun', '4.2 Photosynthesis', '25.2 Using Electromagnetism', '22.2 Optics', 'revolutions of earth', '7.4 History of Life on Earth', 'changes of state', '1.4 The Microscope', '24.2 Earth as a Magnet', 'nucleic acid classification', '18.2 Cycles of Matter', '20.2 The Senses', '12.2 Flatworms and Roundworms', 'rotation of earth', '17.3 The Digestive System', '7.3 Covalent Bonds', 'law of reflection', '13.3 Groundwater', '18.2 Transfer of Thermal Energy', '4.3 Changes of State', 'clouds', '12.5 Echinoderms and Invertebrate Chordates', '13.2 Fish', '21.3 First Two Lines of Defense', '9.2 Soils', '6.4 Theory of Plate Tectonics', '6.1 How Elements Are Organized', '11.3 Absolute Ages of Rocks', '9.4 Biochemical Reactions', '22.3 Vision', '3.2 Cell Structures', 'greenhouse effect', '21.3 The Electromagnetic Spectrum', '16.2 The Integumentary System', '11.2 Relative Ages of Rocks', '7.2 Ionic Bonds', '24.1 Flow of Energy', '19.3 Wave Interactions and Interference', '24.2 Cycles of Matter', '11.3 Nuclear Energy', '9.2 Fungi', 'seasons', '14.2 Ocean Movements', '23.3 Electric Circuits', '12.3 Acceleration', '25.1 Introduction to the Solar System', '7.1 Introduction to Chemical Bonds', '6.2 Continental Drift', '22.3 Reproduction and Life Stages', '17.1 Climate and Its Causes', '8.3 Types of Volcanoes', '20.1 The Nervous System', '16.3 The Skeletal System', '21.4 Immune System Defenses', '4.1 Types of Rocks', '4.1 Solids Liquids Gases and Plasmas', 'nails and hair', '19.2 Measuring Waves', '14.1 Introduction to the Oceans', '22.1 Male Reproductive System', '6.1 Inside Earth', '9.1 Protists', 'magnetic evidence for seafloor spreading', '10.4 Erosion and Deposition by Glaciers', '19.1 The Respiratory System', '16.4 The Muscular System', '22.2 Effects of Air Pollution', '5.1 Inside the Atom', '10.1 Erosion and Deposition by Flowing Water', '11.1 Fossils', '24.4 The Sun and the EarthMoon System', '22.1 Air Pollution'])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_descriptions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# with open(output_dir + 'ck12_dataset_beta_v4.json', 'w') as f:\n",
    "#     json.dump(ck12_combined_dataset, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# with open(output_dir + 'ck12_dataset_beta_v4.json', 'r') as f:\n",
    "#     ck12_combined_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Test spelling and grammar fixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def check_mispelled(word):\n",
    "    return word and word.isalpha() and not (edict.check(word) or anglo_edict.check(word) or edict.check(word[0].upper() + word[1:]))\n",
    "\n",
    "def correct_spelling_error(misspelled_word, suggested_spellings):\n",
    "    highest_ratio = 0\n",
    "    closest_match = None\n",
    "    for word in suggested_spellings:\n",
    "        match_r = fuzz.ratio(misspelled_word, word)\n",
    "        if match_r >= highest_ratio and (word[0] == misspelled_word[0] or not check_mispelled(word[0] + misspelled_word)) and len(misspelled_word) <= len(word):\n",
    "            highest_ratio = match_r\n",
    "            closest_match = word\n",
    "            break\n",
    "    spell_changes[misspelled_word] = closest_match\n",
    "    return closest_match\n",
    "\n",
    "def apply_spelling_fix(orig_text):\n",
    "    orig_text_tokens = orig_text.split()\n",
    "    processed_tokens = []\n",
    "    for token in orig_text_tokens:\n",
    "        norm_token = token.lower()\n",
    "        if len(norm_token) < 4:\n",
    "            processed_tokens.append(token)\n",
    "            continue\n",
    "        if check_mispelled(norm_token):\n",
    "            suggested_replacements = edict.suggest(token)\n",
    "            replacement_text = correct_spelling_error(norm_token, suggested_replacements)\n",
    "            if replacement_text:\n",
    "                if norm_token[0].isupper():\n",
    "                    replacement_text = upper(replacement_text[0]) + replaced_text[1:]\n",
    "                processed_tokens.append(replacement_text)\n",
    "            else:\n",
    "                processed_tokens.append(token)\n",
    "        else:\n",
    "            processed_tokens.append(token)\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "def diff_corrected_text(orig_text, corrected_text):\n",
    "    diff = dmp.diff_main(orig_text, corrected_text)\n",
    "    return HTML(dmp.diff_prettyHtml(diff))\n",
    "\n",
    "def specify_lesson_q_path(lesson):\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dmp = diff_match_patch.diff_match_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ck12_spell_gramm_fix_test = deepcopy(ck12_combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "gram_checker = language_check.LanguageTool('en-US')\n",
    "gram_checker.disabled = set(['SENT_START_CONJUNCTIVE_LINKING_ADVERB_COMMA', 'POSSESSIVE_APOSTROPHE', 'A_PLURAL'])\n",
    "gram_checker.disable_spellchecking()\n",
    "\n",
    "punc_set_space = set([',', ':', ';', '/\"'])\n",
    "punc_set_nospace = set(['-', '\\'', '-', '?', '.', '!'])\n",
    "question_enders = set(['.', '?', ':'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#check descriptions\n",
    "spell_changes = {}\n",
    "unaltered_text = []\n",
    "replaced_text = []\n",
    "for lesson in list(ck12_spell_gramm_fix_test['life-science'].values()):\n",
    "    if lesson['instructionalDiagrams']:\n",
    "        for diagram, description in lesson['instructionalDiagrams'].items():\n",
    "            orig_text = description['processedText']\n",
    "            spell_fixed_text = apply_spelling_fix(orig_text)\n",
    "            for punc_char in punc_set_nospace:\n",
    "                spell_fixed_text = spell_fixed_text.replace(' ' + punc_char + ' ' , punc_char)\n",
    "            for punc_char in punc_set_space:\n",
    "                spell_fixed_text = spell_fixed_text.replace(' ' + punc_char + ' ' , punc_char + ' ')\n",
    "            gram_fixed = gram_checker.correct(spell_fixed_text)\n",
    "            if gram_fixed != orig_text:\n",
    "                unaltered_text.append(orig_text)\n",
    "                replaced_text.append(gram_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spell_changes = {}\n",
    "unaltered_text = []\n",
    "replaced_text = []\n",
    "for lesson in list(ck12_spell_gramm_fix_test['life-science'].values()):\n",
    "    if lesson['questions']['nonDiagramQuestions']:\n",
    "        for diagram, description in lesson['questions']['diagramQuestions'].items():\n",
    "            orig_text = description['beingAsked']['processedText']\n",
    "            spell_fixed_text = apply_spelling_fix(orig_text)\n",
    "            gram_fixed = gram_checker.correct(spell_fixed_text)\n",
    "            for punc_char in punc_set_nospace:\n",
    "                gram_fixed = gram_fixed.replace(' ' + punc_char + ' ' , punc_char)\n",
    "                gram_fixed = gram_fixed.replace(' ' + punc_char, punc_char)\n",
    "            for punc_char in punc_set_space:\n",
    "                gram_fixed = gram_fixed.replace(' ' + punc_char + ' ' , punc_char + ' ')\n",
    "            if gram_fixed[-1] not in question_enders:\n",
    "                if gram_fixed.split()[0] in ['Identify', 'Name'] or '__' in gram_fixed:\n",
    "                    gram_fixed += '.'\n",
    "                else:\n",
    "                    gram_fixed += '?'\n",
    "            if gram_fixed != orig_text:\n",
    "                unaltered_text.append(orig_text)\n",
    "                replaced_text.append(gram_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "1207\n"
     ]
    }
   ],
   "source": [
    "comp_text = list(zip(unaltered_text, replaced_text))\n",
    "\n",
    "print(len(spell_changes))\n",
    "print(len(comp_text))\n",
    "# spell_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where is the thymus?\n",
      "\n",
      "Where is the thymus?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">w</del><ins style=\"background:#e6ffe6;\">W</ins><span>here is the thymus?</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_idx = np.random.randint(len(comp_text))\n",
    "print(unaltered_text[rand_idx])\n",
    "print()\n",
    "print(replaced_text[rand_idx])\n",
    "diff_corrected_text(*comp_text[rand_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# with open(output_dir + 'ck12_dataset_beta_v4.json', 'r') as f:\n",
    "#     ck12_combined_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Topic key collisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### old nested structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['earth-science', 'physical-science', 'life-science'])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexbook_ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "build_website_lessons = [list(lesson.keys()) for lesson in lessons_ds.values()]\n",
    "website_lessons= sorted([item for sublist in build_website_lessons for item in sublist])\n",
    "\n",
    "build_flexbook_lessons = [list(lesson.keys()) for lesson in flexbook_ds.values()]\n",
    "flexbook_lessons= [item for sublist in build_flexbook_lessons for item in sublist]\n",
    "flexbook_lessons = sorted([lesson.split(maxsplit=1)[1].strip().lower() for lesson in flexbook_lessons])\n",
    "fbls = set(flexbook_lessons)\n",
    "wsls = set(website_lessons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_dd_lessons = len(fbls.union(wsls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_all_lessons = len(website_lessons + flexbook_lessons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_all_lessons - n_dd_lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flexbook_lessons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "print(len(flexbook_lessons))\n",
    "print(len(set(flexbook_lessons)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.Series(flexbook_lessons).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined_lesson_series = pd.Series(flexbook_lessons + website_lessons)\n",
    "lessons_with_name_dupes = combined_lesson_series.value_counts()[combined_lesson_series.value_counts() > 1].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lessons_with_name_dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829\n",
      "829\n"
     ]
    }
   ],
   "source": [
    "print(len(website_lessons))\n",
    "print(len(set(website_lessons)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(website_lessons).union(set(flexbook_lessons)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "build_website_topics = [list(lesson.keys()) for lesson in lessons_ds.values()]\n",
    "website_topics= sorted([item for sublist in build_website_lessons for item in sublist])\n",
    "\n",
    "# build_flexbook_topics = [list(lesson.keys()) for lesson in flexbook_ds.values()]\n",
    "# flexbook_topics= [item for sublist in build_flexbook_lessons for item in sublist]\n",
    "# flexbook_lessons = sorted([lesson.split(maxsplit=1)[1].strip().lower() for lesson in flexbook_lessons])\n",
    "# fbls = set(flexbook_lessons)\n",
    "# wsls = set(website_lessons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### with new flat dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_list = []\n",
    "for lesson in complete_flat_ds:\n",
    "#     for t_id, topic in lesson['topics'].items():\n",
    "    topic_list.append(lesson['lessonName'].lower())\n",
    "\n",
    "topic_tokens = {idx: [word for word in val.split() if word not in cached_sw] for idx, val in enumerate(topic_list)}\n",
    "\n",
    "token_to_topic_index = defaultdict(list)\n",
    "for k, vals in topic_tokens.items():\n",
    "    for v in vals:\n",
    "        token_to_topic_index[v].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "collision_dict = {token: topic_idxs for token, topic_idxs in token_to_topic_index.items() if len(topic_idxs) < 50 and len(topic_idxs) > 10}\n",
    "build_topics_collision_idxs = collision_dict.values()\n",
    "topics_collision_idxs = [item for sublist in build_topics_collision_idxs for item in sublist]\n",
    "topics_w_collisions_set = set(topics_collision_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for k, v in collision_dict.items():\n",
    "    for topic_idx in v:\n",
    "        print(topic_list[topic_idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lmtizer.stem('plants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lesson_names = [lesson['lessonName'].lower() for lesson in complete_flat_ds]\n",
    "lesson_idx_lookup = {v: k for k, v in enumerate(lesson_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lmtizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ignore_tokens = ['introduction', 'form', 'component', 'destruction', 'destruction']\n",
    "cached_sw = stopwords.words(\"english\") + list(string.punctuation)\n",
    "def find_meta_lessons(complete_ds):\n",
    "    meta_lesson_id = 0\n",
    "    meta_lesson_prefix = 'MT_'\n",
    "\n",
    "    lesson_names = [lesson['lessonName'].lower() for lesson in complete_ds]\n",
    "    lesson_tokens = {idx: filter_tokens(val) for idx, val in enumerate(lesson_names)}\n",
    "    token_to_lesson_index = defaultdict(list)\n",
    "    \n",
    "    for k, vals in lesson_tokens.items():\n",
    "        for v in vals:\n",
    "            token_to_lesson_index[v].append(k)\n",
    "            \n",
    "    collision_dict = {token: topic_idxs for token, topic_idxs in token_to_lesson_index.items() if len(topic_idxs) < 20 and len(topic_idxs) > 1}\n",
    "    return collision_dict\n",
    "\n",
    "def pick_rarest_metalesson(metalessons):\n",
    "    return sorted({k: meta_topic_sizes[k] for k in metalessons}.items(), key=lambda x: x[1])[0][0]\n",
    "\n",
    "def filter_pos(token_list):\n",
    "    tagged_tokens = nltk.pos_tag(token_list)\n",
    "    filtered_tokes = [toke[0] for toke in tagged_tokens if toke[1] in ['NN', 'RB', 'NNS', 'JJ']]\n",
    "    if filtered_tokes:\n",
    "        return filtered_tokes\n",
    "    else:\n",
    "        return ['aaa_none']\n",
    "\n",
    "def filter_tokens(tokens):\n",
    "    return filter_pos([lmtizer.lemmatize(toke) for toke in tokens.split() if toke not in cached_sw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "col_dict = find_meta_lessons(complete_flat_ds)\n",
    "\n",
    "meta_topic_sizes = {v[0]: len(v[1])for v in sorted(col_dict.items(), key=lambda x: len(x[1]), reverse=True)}\n",
    "\n",
    "token_to_lesson_index = defaultdict(list)\n",
    "for k, vals in col_dict.items():\n",
    "    for v in vals:\n",
    "        token_to_lesson_index[v].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "meta_lesson_assignments = {}\n",
    "for lesson in lesson_names:\n",
    "    associated_metalessons = token_to_lesson_index[lesson_idx_lookup[lesson]]\n",
    "    if associated_metalessons:\n",
    "        meta_lesson_assignments[lesson] = pick_rarest_metalesson(associated_metalessons)\n",
    "    else:\n",
    "        meta_lesson_assignments[lesson] = ' '.join(filter_tokens(lesson))\n",
    "\n",
    "meta_lesson_string_ids = set(meta_lesson_assignments.values())\n",
    "meta_lesson_id_lookup =  {val: idx for idx, val in enumerate(meta_lesson_string_ids)}\n",
    "meta_lesson_id_assignments = {k: meta_lesson_id_lookup[v] for k, v in meta_lesson_assignments.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(len(token_to_lesson_index.keys()))\n",
    "\n",
    "# match_seq = pd.Series([len(tokens) for tokens in token_to_lesson_index.values()])\n",
    "# match_seq.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linked_lessons = defaultdict(list)\n",
    "for k, v in meta_lesson_assignments.items():\n",
    "    linked_lessons[v].append(k)\n",
    "linked_lessons = dict(linked_lessons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(meta_lesson_assignments.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %page linked_lessons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ttl = ['respiration', 'reproductive', 'animal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filter_pos(ttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nltk.pos_tag([' current', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refinements to make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "get viz working\n",
    "return annotations to ds\n",
    "fix lessons missing topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file i/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "write_file('build_v5_2f.json', complete_flat_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write_file('build_v5_prior_to_refinement.json', ck12_combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../dataset_releases/data_release_beta5/inter/tqa_dataset_beta5.json', 'r') as f:\n",
    "    prev_v5 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# with open('build_v5.pkl', 'wb') as f:\n",
    "#     pickle.dump(ck12_combined_dataset ,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#print(topics_to_remove) #specicied in match topics section above, explictly set here\n",
    "\n",
    "structural_topics = ['Summary', 'Review', 'References', 'Explore More', 'Lesson Summary', 'Lesson Objectives', 'Points to Consider', 'Introduction',\n",
    "                    'Recall', 'Apply Concepts', 'Think Critically', 'Resources', 'Explore More II', 'Explore More I', 'Explore More III']\n",
    "\n",
    "vocab_topics = ['Lesson Vocabulary', 'Vocabulary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "code_folding": [
     141
    ],
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def iterate_over_all_material(complete_ds, apply_function):\n",
    "    lesson_returns = []\n",
    "    for subject, lessons in sorted(complete_ds.items(), key= lambda x: x[0]):\n",
    "        for lesson_name, lesson_content in sorted(lessons.items(), key= lambda x: x[0]):\n",
    "            response = apply_function(lesson_name, lesson_content)\n",
    "            if response:\n",
    "                lesson_returns.append(response)\n",
    "    return lesson_returns\n",
    "            \n",
    "def apply_fixes(lesson_name, lesson_content):\n",
    "    struct_content, vocab_content = iterate_over_text(lesson_content['topics'], lesson_name)\n",
    "    lesson_content['adjunctTopics'] = struct_content\n",
    "    lesson_content['adjunctTopics']['Vocabulary'] = vocab_content\n",
    "    iterate_over_text_questions(lesson_content['questions']['nonDiagramQuestions'])\n",
    "    if lesson_content['instructionalDiagrams']:\n",
    "        if not lesson_content['questions']['diagramQuestions']:\n",
    "            print(lesson_name + ' missing questions')\n",
    "        iterate_over_diagram_questions(lesson_content['questions']['diagramQuestions'])\n",
    "        iterate_over_diagram_descriptions(lesson_content['instructionalDiagrams'])\n",
    "            \n",
    "def iterate_over_text(topic_sections, lesson_name=None):\n",
    "    structural_content = {}\n",
    "    vocab_section = {}\n",
    "    topics_to_remove = []\n",
    "    for topic, content in sorted(topic_sections.items(), key= lambda x: x[1]['orderID']):\n",
    "        if content['content']['figures']:\n",
    "            iterate_over_textbook_figs(content['content']['figures'], lesson_name)\n",
    "        if topic in vocab_topics:\n",
    "            vocab_section.update(add_defintions_to_vocab(content))\n",
    "            topics_to_remove.append(topic)\n",
    "        elif topic in structural_topics:\n",
    "            structural_content[topic] = content\n",
    "            topics_to_remove.append(topic)\n",
    "    for topic in topics_to_remove:\n",
    "        topic_sections.pop(topic)\n",
    "    return structural_content, vocab_section\n",
    "    \n",
    "\n",
    "def iterate_over_text_questions(text_questions):\n",
    "    replace_local_ids_w_global(text_questions, 'text', True, 'id')\n",
    "            \n",
    "def iterate_over_diagram_questions(diagram_questions):\n",
    "    for qid, question in diagram_questions.items():\n",
    "        replace_uri_with_path(question, 'question_images')\n",
    "        orig_question= question['beingAsked']['processedText']\n",
    "        fixed_question = apply_spelling_and_grammar_fixes(orig_question)\n",
    "        if fixed_question:\n",
    "            question['beingAsked']['processedText'] = fixed_question\n",
    "        if detect_abc_question(question):\n",
    "            standardize_abc_question(question)\n",
    "    replace_local_ids_w_global(diagram_questions, 'diagram', True, 'id')\n",
    "\n",
    "def iterate_over_diagram_descriptions(diagram_descriptions, description_path_prefix=None):\n",
    "    for diagram_name, diagram_content in diagram_descriptions.items():\n",
    "        replace_uri_with_path(diagram_content, 'teaching_images')\n",
    "        orig_description = diagram_content['processedText']\n",
    "        fixed_description = apply_spelling_and_grammar_fixes(orig_description)\n",
    "        if fixed_description:\n",
    "            diagram_content['processedText'] = fixed_description\n",
    "    replace_local_ids_w_global(diagram_descriptions, 'description', True, z_pad=4)\n",
    "\n",
    "            \n",
    "def add_defintions_to_vocab(vocab_section): #done\n",
    "    lesson_vocab = {}\n",
    "    for word in vocab_section['content']['text'].split('\\n'):\n",
    "        if word in flexbook_glossary.keys():\n",
    "            lesson_vocab[word] = flexbook_glossary[word]\n",
    "        elif word:\n",
    "            lesson_vocab[word] = ''\n",
    "    return lesson_vocab\n",
    "\n",
    "def add_global_ids(data_object, object_type, zero_padding=6): #done\n",
    "    id_prefix = {'text': 'NDQ_', 'diagram': 'DQ_', 'lesson': 'L_', 'description': 'DD_', 'topics': 'T_'}\n",
    "    global_ids_counters[object_type] += 1\n",
    "    data_object['globalID'] = id_prefix[object_type] + str(global_ids_counters[object_type]).zfill(zero_padding)\n",
    "\n",
    "def detect_abc_question(question):\n",
    "    abc_choices = [ac['processedText'] for ac in question['answerChoices'].values() if ac['processedText'] in list(string.ascii_letters)]\n",
    "    return len(abc_choices) == 4\n",
    "\n",
    "def standardize_abc_question(question): #done\n",
    "    question['imagePath'] = question['imagePath'].replace('question_images', 'abc_question_images')\n",
    "    question['correctAnswer']['processedText'] = question['correctAnswer']['processedText'].upper()\n",
    "    for ac in question['answerChoices'].values():\n",
    "        ac['processedText'] = ac['processedText'].upper()\n",
    "    \n",
    "def iterate_over_textbook_figs(figure_content, lesson_n): # done\n",
    "    for figure in sorted(figure_content, key= lambda x: x['image_uri'].split('/')[-1]):\n",
    "        replace_uri_with_path(figure, 'textbook_images', lesson_n)\n",
    "        \n",
    "def replace_uri_with_path(image_content, path_prefix, lesson_name=None): # done\n",
    "    image_key_str = 'imageUri'\n",
    "    if 'image_uri' in image_content.keys():\n",
    "        image_key_str = 'image_uri'\n",
    "#     print(image_content[image_key_str])\n",
    "    image_name = image_content[image_key_str].split('/')[-1]\n",
    "#     print(image_name)\n",
    "    image_number = image_name.split('_')[-1].split('.')[0]\n",
    "    image_content.pop(image_key_str)\n",
    "    if lesson_name:\n",
    "        global_ids_counters['image'] += 1\n",
    "        prev_image_name = deepcopy(image_name)\n",
    "        image_name =  rename_lesson(lesson_name).replace(' ', '_') + '_' + str(global_ids_counters['image']) + '.png'\n",
    "        record_image_name_changes[os.path.join(path_prefix, prev_image_name)] = os.path.join(path_prefix, image_name)\n",
    "    image_content['imagePath'] = os.path.join(path_prefix, image_name)\n",
    "      \n",
    "def apply_spelling_and_grammar_fixes(orig_text): #done\n",
    "    spell_fixed_text = apply_spelling_fix(orig_text)\n",
    "    for punc_char in punc_set_nospace:\n",
    "        spell_fixed_text = spell_fixed_text.replace(' ' + punc_char + ' ' , punc_char)\n",
    "    for punc_char in punc_set_space:\n",
    "        spell_fixed_text = spell_fixed_text.replace(' ' + punc_char + ' ' , punc_char + ' ')\n",
    "    gram_fixed = gram_checker.correct(spell_fixed_text)\n",
    "    if gram_fixed != orig_text:\n",
    "        return gram_fixed\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def replace_local_ids_w_global(data_unit, unit_type, keys_too=False, id_key='', z_pad=6):\n",
    "    if id_key:\n",
    "        objs_to_iterate = sorted(data_unit.items(), key=lambda x: x[1][id_key])\n",
    "    else:\n",
    "        objs_to_iterate = data_unit.items()\n",
    "    for k, v in objs_to_iterate:\n",
    "        add_global_ids(v, unit_type, zero_padding=z_pad)\n",
    "        if id_key:\n",
    "            v.pop(id_key)\n",
    "        if keys_too:\n",
    "            data_unit[v['globalID']] = v\n",
    "            data_unit.pop(k)\n",
    "            if unit_type == 'topics':\n",
    "                name_field = unit_type[:-1] + 'Name'\n",
    "                v[name_field] = k\n",
    "    pass\n",
    "\n",
    "def rename_lesson(lesson_name):\n",
    "    if lesson_name[0].isdigit():\n",
    "        return lesson_name.split(maxsplit=1)[1].strip().lower()\n",
    "    else:\n",
    "        return lesson_name\n",
    "\n",
    "def flatten_complete_ds(lesson_name, lesson_content):\n",
    "    lesson_content['lessonName'] =lesson_name\n",
    "    add_global_ids(lesson_content, 'lesson', 4)\n",
    "    lesson_content['lessonName'] = rename_lesson(lesson_name)\n",
    "    obj_key = 'topics'\n",
    "    replace_local_ids_w_global(lesson_content[obj_key], obj_key, True, 'orderID', 4)\n",
    "    return lesson_content\n",
    "\n",
    "def add_metalesson_ids(lesson, meta_lesson_assignments):\n",
    "    lesson['metaLessonID'] = 'ML_' + str(meta_lesson_assignments[lesson['lessonName']]).zfill(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "full_test_ds = deepcopy(ck12_combined_dataset)\n",
    "test_vals= {k: v  for k, v in list(full_test_ds['earth-science'].items())[:20]}\n",
    "buid_test_cds = {}\n",
    "buid_test_cds['earth-science'] = test_vals\n",
    "test_cds = deepcopy(buid_test_cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 s, sys: 2.77 s, total: 16.7 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dq_gid = 0\n",
    "ndq_gid = 0\n",
    "l_id = 0\n",
    "t_id = 0\n",
    "dd_id = 0\n",
    "pd_image = 20000\n",
    "\n",
    "record_image_name_changes = {}\n",
    "global_ids_counters = {'text': ndq_gid, 'diagram': ndq_gid, 'lesson': l_id, 'topics': t_id, 'description': dd_id, 'image':pd_image}\n",
    "_ = iterate_over_all_material(full_test_ds, apply_fixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "complete_flat_ds = iterate_over_all_material(full_test_ds, flatten_complete_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lesson in complete_flat_ds:\n",
    "    add_metalesson_ids(lesson, meta_lesson_id_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML_0343'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_flat_ds[40]['metaLessonID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_l_set = [len(lesson['questions']['nonDiagramQuestions']) for lesson in complete_flat_ds]\n",
    "old_l_set = [len(lesson['questions']['nonDiagramQuestions'])  for lesson in prev_v5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18944"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(old_l_set).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18944"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(new_l_set).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(old_l_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# complete_flat_ds[0].keys()\n",
    "# complete_flat_ds[0]['questions']\n",
    "# sorted(complete_flat_ds[9]['instructionalDiagrams'].items(), key=lambda x: x[1]['globalID'])\n",
    "# sorted(complete_flat_ds[0]['questions']['nonDiagramQuestions'].items(), key=lambda x: x[1]['globalID'])\n",
    "# complete_flat_ds[0]['adjunctTopics']\n",
    "# list(complete_flat_ds[0]['topics'].items())[5]\n",
    "# complete_flat_ds[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_ids_seen = []\n",
    "q_ids_seen = []\n",
    "for lesson in list(list(test_cds.values())[0].values()):\n",
    "    for que in lesson['questions']['nonDiagramQuestions'].values():\n",
    "        t_ids_seen.append(que['globalID'])  \n",
    "for lesson in list(list(test_cds.values())[0].values()):\n",
    "    for que in lesson['questions']['diagramQuestions'].values():\n",
    "        q_ids_seen.append(que['globalID'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(test_cds['earth-science'].values())[0]['topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(test_cds['earth-science'].values())[0]['adjunctTopics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#             print(lesson_content['topics'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# renaming diagram image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_base = '../dataset_releases/data_release_beta4_standard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset_releases/data_release_beta4_standard/textbook_images/Liquids_Water_and_Other_Liquids_0004_fig_1.1.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Predicting_Volcanic_Eruptions_Gas_Emissions_0004_fig_1.1.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Carbon_Monomers_and_Polymers_Natural_Carbon_Polymers_0004_fig_1.2.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Weathering_and_Erosion_Weathering_Takes_Time_0004_fig_1.1.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/4.2_Behavior_of_Gases_What_Is_Pressure_0086_fig_4.11.png\n",
      "False\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/1.1_Scientific_Ways_of_Thinking_Thinking_Like_a_Scientist_0012_fig_1.1.png\n",
      "False\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Lizards_and_Snakes_How_do_Snakes_Eat_0007_fig_1.6.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Principle_of_Uniformitarianism_Answer_a_Question__Earth_History_0004_fig_1.2.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Earths_Layers_Layers_by_Mechanical_Properties_0004_fig_1.1.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/16.2_The_Integumentary_System_Structure_of_the_Skin_0394_fig_16.6.png\n",
      "False\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Mammal_Classification_Groups_of_Mammals_0004_fig_1.2.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Landforms_from_Erosion_and_Deposition_by_Gravity_Slump_and_Creep_0005_fig_1.2.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/20.3_Using_Sound_Echolocation_0467_fig_20.13.png\n",
      "False\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Lymphatic_System_Lymph_Organs_0005_fig_1.2.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/9.2_Fungi_Fungi_Reproduction_0222_fig_9.9.png\n",
      "False\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Wind_Waves_Shape_of_a_Wave_0004_fig_1.1.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Plant_Reproduction_and_Life_Cycle_Plant_Reproduction_and_Life_Cycle_0004_fig_1.1.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/Intrusive_and_Extrusive_Igneous_Rocks_Intrusive_Igneous_Rocks_0004_fig_1.1.png\n",
      "True\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/18.3_The_Human_Population_Recent_Population_Growth_0482_fig_18.19.png\n",
      "False\n",
      "../dataset_releases/data_release_beta4_standard/textbook_images/25.2_Inner_Planets_Volcanoes_0631_fig_25.11.png\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "missing = []\n",
    "for old_name, new_name in list(record_image_name_changes.items())[:20]:\n",
    "    try:\n",
    "        old_path = os.path.join(image_base, old_name)\n",
    "        new_path = os.path.join(image_base, new_name)\n",
    "        print(old_path)\n",
    "        print(os.path.exists(old_path))\n",
    "#         os.rename(old_path, new_path)\n",
    "    except FileNotFoundError:\n",
    "        missing.append(old_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(image_base + record_image_name_changes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3050"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(record_image_name_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Splitting experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# flexbook_glossary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# print(list(diagram_lesson_lookup.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test_lesson = ck12_combined_dataset['earth-science']['24.1 Planet Earth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# pprint.pprint(test_lesson['instructionalDiagrams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "list(test_lesson['instructionalDiagrams'].values())[0]['processedText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test_lesson['topics'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test_vocab = test_lesson['topics']['Vocabulary']['content']['text'].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for word in test_vocab:\n",
    "    if word in flexbook_glossary:\n",
    "        print(flexbook_glossary[word])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# write_file('ck12_v4_5.json', ck12_combined_dataset, 'experimental_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
