{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Table of Contents\n",
    "* &nbsp;\n",
    "\t* [imports](#imports)\n",
    "\t* [simple functions](#simple-functions)\n",
    "* [Load data](#Load-data)\n",
    "\t* [setting paths](#setting-paths)\n",
    "\t* [parsed content and raw questions and descriptions](#parsed-content-and-raw-questions-and-descriptions)\n",
    "\t* [localization and recognition](#localization-and-recognition)\n",
    "\t* [building spellings and grammar](#building-spellings-and-grammar)\n",
    "* [Clean and prepare data](#Clean-and-prepare-data)\n",
    "\t* [extract media links](#extract-media-links)\n",
    "\t* [remove non-conforming content](#remove-non-conforming-content)\n",
    "\t\t* [code](#code)\n",
    "\t\t* [run](#run)\n",
    "\t* [remove recognition and localization errors](#remove-recognition-and-localization-errors)\n",
    "* [Add image annotations](#Add-image-annotations)\n",
    "\t* [localization](#localization)\n",
    "\t* [recognition](#recognition)\n",
    "\t\t* [code](#code)\n",
    "\t\t* [run](#run)\n",
    "\t\t* [hide](#hide)\n",
    "* [Integrate diagram questions and descriptions](#Integrate-diagram-questions-and-descriptions)\n",
    "\t* [match diagram topics to lessons](#match-diagram-topics-to-lessons)\n",
    "\t\t* [code](#code)\n",
    "\t\t* [run](#run)\n",
    "\t\t* [hide](#hide)\n",
    "\t* [merge questions](#merge-questions)\n",
    "\t\t* [code](#code)\n",
    "\t\t* [run](#run)\n",
    "\t\t* [hide](#hide)\n",
    "\t* [merge descriptions](#merge-descriptions)\n",
    "\t\t* [hide](#hide)\n",
    "\t* [Apply spelling and grammar fixes](#Apply-spelling-and-grammar-fixes)\n",
    "\t\t* [code](#code)\n",
    "\t\t* [run](#run)\n",
    "\t\t* [hide](#hide)\n",
    "* [Topic key collisions](#Topic-key-collisions)\n",
    "* [Refinements to make](#Refinements-to-make)\n",
    "* [End](#End)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pylab as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext base16_mplrc\n",
    "# %base16_mplrc light solarized\n",
    "%base16_mplrc dark solarized\n",
    "plt.rcParams['grid.linewidth'] = 0\n",
    "plt.rcParams['figure.figsize'] = (16.0, 10.0)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from scipy.stats.mstats import mode\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import pprint\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import io\n",
    "import sys\n",
    "import os\n",
    "from binascii import b2a_hex\n",
    "import base64\n",
    "from wand.image import Image as WImage\n",
    "from IPython.display import display\n",
    "from IPython.core.display import HTML\n",
    "import PIL.Image as Image\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import language_check\n",
    "import enchant\n",
    "import difflib\n",
    "import diff_match_patch\n",
    "import fuzzywuzzy.fuzz as fuzz\n",
    "import re\n",
    "import jsonschema\n",
    "from pdfextraction.ck12_schema import ck12_schema as schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## simple functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def write_file(filename, data_dict, output_dir='output_data_from_nbs'):\n",
    "    with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "        json.dump(data_dict, f, indent=4, sort_keys=True)\n",
    "        \n",
    "def get_img_n(image_name):\n",
    "    return [re.findall(\"[0-9]+\", image_name)][0][0]\n",
    "\n",
    "def clean_list(dir_path):\n",
    "    hidden_removed = filter(lambda f: not f.startswith('.'), os.listdir(dir_path))\n",
    "    return [topic.replace('_diagram', '') for topic in hidden_removed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "output_dir = 'output_data_from_nbs/'\n",
    "raw_data_dir = '../spare5_produced_data/data/'\n",
    "raw_dq_file = 'ai2_testquestions_20161005.csv'\n",
    "s5_raw_decriptions = 'ai2_diagramdescriptions_20161018.csv'\n",
    "ai2_raw_decriptions = 'our_description.csv'\n",
    "glossary_path = os.path.join(output_dir, 'flexbook_glossary.pkl')\n",
    "\n",
    "turk_proc_dir = '/Users/schwenk/wrk/stb/diagram_questions/turk_processing/'\n",
    "metadata_dir = turk_proc_dir + 'store_hit_results_metadata/'\n",
    "lc_results_dir = 'loc_group_3'\n",
    "box_loc_joined = 'loc_annotations'\n",
    "recog_results_dir = 'group_latest_combined'\n",
    "\n",
    "box_choices_1_dir = 'final_text_boxes_fixed'\n",
    "box_choices_2_dir = 'final_text_boxes_pass_2'\n",
    "none_agree = 'no_turkers_agree_lookup.pkl'\n",
    "two_agree_lookup = 'two_turkers_agree_lookup.pkl'\n",
    "all_agree_lookup = 'user_diag_loopkup.pkl'\n",
    "\n",
    "recog_performed = '/Users/schwenk/wrk/stb/diagram_questions/turk_processing/final_diagrams/'\n",
    "all_dir = '/Users/schwenk/wrk/stb/ai2-vision-textbook-dataset/diagrams/tqa_diagrams_v0.9/'\n",
    "pruned_dir = '/Users/schwenk/wrk/stb/ai2-vision-textbook-dataset/diagrams/dataset_Sep_27/tqa_diagrams_v0.9_question_images/'\n",
    "description_dir = '/Users/schwenk/wrk/stb/spare5_produced_data/tqa_diagrams_v0.9_inbook/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## parsed content and raw questions and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# load complete text v 3.5, raw diagram questions and descriptions\n",
    "with open(output_dir + 'ck12_dataset_beta_v3_5.json', 'r') as f:\n",
    "    ck12_combined_dataset_raw = json.load(f)\n",
    "with open(output_dir + 'ck12_flexbook_only_beta_v3.json', 'r') as f:\n",
    "    flexbook_ds = json.load(f)\n",
    "with open(output_dir + 'ck12_lessons_only_beta_v3.json', 'r') as f:\n",
    "    lessons_ds = json.load(f)\n",
    "\n",
    "# loading questions\n",
    "desc_df = pd.read_csv(raw_data_dir + s5_raw_decriptions, encoding='latin-1')\n",
    "desc_df['diagram'] = desc_df['reference_id'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "ai2_raw_decriptions_df = pd.read_csv(raw_data_dir + ai2_raw_decriptions, encoding='latin-1')\n",
    "ai2_written_df_completed = ai2_raw_decriptions_df[['Topic', 'Image Path', 'Description']]\n",
    "ai2_written_df_completed['diagram'] = ai2_written_df_completed['Image Path'].apply(lambda x: x.split('/')[-1])\n",
    "ai2_written_df_completed['topic'] = ai2_written_df_completed['Topic']\n",
    "del  ai2_written_df_completed['Topic']\n",
    "\n",
    "#loading questions\n",
    "q_col = '03_write_question'\n",
    "r_ans_col = '04_write_right_answer'\n",
    "w_ans_col = '05_write_wrong_answers'\n",
    "data_cols = [q_col, r_ans_col, w_ans_col]\n",
    "raw_dq_df = pd.read_csv(raw_data_dir + raw_dq_file, encoding='latin-1')\n",
    "dr_proc_df = raw_dq_df.copy()\n",
    "dr_proc_df['wac_list'] = dr_proc_df[w_ans_col].apply(lambda x: json.loads(x))\n",
    "dr_proc_df['diagram'] = dr_proc_df['reference_id'].apply(lambda x: x.split('/')[-1])\n",
    "dr_proc_df['topic'] = dr_proc_df['reference_id'].apply(lambda x: x.split('/')[-1].rsplit('_', maxsplit=1)[0])\n",
    "\n",
    "with open('../diagram_questions/topic_match_terms.json', 'r') as f:\n",
    "    topic_term_match = json.load(f)    \n",
    "\n",
    "with open(glossary_path, 'rb') as f:\n",
    "    flexbook_glossary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### localization and recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loc_res_df = pd.read_pickle(os.path.join(metadata_dir, lc_results_dir, 'complete_df.pkl'))\n",
    "recog_res_df = pd.read_pickle(os.path.join(metadata_dir, recog_results_dir, 'recog_df.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## building spellings and grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# loading spelling defs\n",
    "with open(output_dir + 'ck_12_vocab_words.pkl', 'rb') as f:\n",
    "    ck_12_vocab = set(pickle.load(f))\n",
    "with open(output_dir + 'ck_12_all_words.pkl', 'rb') as f:\n",
    "    ck_12_corp = set(pickle.load(f))\n",
    "    \n",
    "with open(output_dir + 'spellings_to_rev.txt', 'r') as f:\n",
    "    whitelisted_words = f.read().split('\\n')[:-1]    \n",
    "with open(output_dir + './desc_spellings_to_rev.txt', 'r') as f:\n",
    "    whitelisted_words += f.read().split('\\n')[:-1]\n",
    "with open(output_dir + './ck_12_spelling_rev.txt', 'r') as f:\n",
    "    whitelisted_words += f.read().split('\\n')[:-1]\n",
    "    \n",
    "ck_12_corp.update(ck_12_vocab)\n",
    "ck_12_corp.update(whitelisted_words)\n",
    "# this must be run later- post loading and processing recog\n",
    "ck_12_corp.update(diagram_rec_corpus)\n",
    "\n",
    "# build spelling dict updated with words from science corpus\n",
    "edict = enchant.Dict(\"en_US\")\n",
    "anglo_edict = enchant.Dict(\"en_UK\")\n",
    "cached_sw = stopwords.words(\"english\") + list(string.punctuation)\n",
    "for word in ck_12_corp:\n",
    "    if word.isalpha() and len(word) > 3:\n",
    "        edict.add(word)\n",
    "        \n",
    "# grammaer checker\n",
    "gram_checker = language_check.LanguageTool('en-US')\n",
    "gram_checker.disabled = set(['SENT_START_CONJUNCTIVE_LINKING_ADVERB_COMMA', 'POSSESSIVE_APOSTROPHE', 'A_PLURAL'])\n",
    "gram_checker.disable_spellchecking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Clean and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## extract media links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ck12_combined_dataset = deepcopy(ck12_combined_dataset_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pat_str = \"(?:https?:\\/\\/(?:www\\.).*?\\s)\"\n",
    "web_link_patern=re.compile(pat_str)\n",
    "\n",
    "def clean_content_text(content_str, web_link_patern):\n",
    "    removed_links = web_link_patern.findall(content_str)\n",
    "    if not removed_links:\n",
    "        return '', ''\n",
    "    split_txt = web_link_patern.split(content_str)\n",
    "    cleaned_text = ' '.join([txt for txt in split_txt if txt])\n",
    "    return cleaned_text, [link.strip() for link in removed_links]\n",
    "\n",
    "def extract_links(complete_ds):\n",
    "    for subject, lessons in complete_ds.items():\n",
    "        for lesson_title, lesson in lessons.items():\n",
    "            for topic, content in lesson['topics'].items():\n",
    "                content_str = content['content']['text']\n",
    "                new_text, links = clean_content_text(content_str, web_link_patern)\n",
    "                content['content']['mediaLinks'] = []\n",
    "                if links:\n",
    "                    content['content']['text'] = new_text\n",
    "                    content['content']['mediaLinks'].extend(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "extract_links(ck12_combined_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## remove non-conforming content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def validate_schema(dataset_json):\n",
    "    errors = []\n",
    "    try:\n",
    "        validator = jsonschema.Draft4Validator(schema)\n",
    "        for error in sorted(validator.iter_errors(dataset_json), key=lambda x: x.absolute_path[0]):\n",
    "            errors.append([error.message, list(error.absolute_path)[:4]])\n",
    "    except jsonschema.ValidationError as e:\n",
    "        errors.append(\"Error in schema --%s-\", e.message)\n",
    "    return errors\n",
    "\n",
    "def validate_dataset(dataset_json):\n",
    "    for subject, flexbook in dataset_json.items():\n",
    "        schema_errors = validate_schema(flexbook)\n",
    "        for lesson_name, lesson in flexbook.items():\n",
    "            ac_errors = check_ac_counts(lesson, subject, lesson_name)\n",
    "        all_errors = schema_errors + ac_errors\n",
    "        if not all_errors:\n",
    "            return 'all validation test passed'\n",
    "        else:\n",
    "            return all_errors\n",
    "\n",
    "def check_ac_counts(lesson_content, subject, lesson_name):\n",
    "    errors = []\n",
    "    for qid, question in lesson_content['questions']['nonDiagramQuestions'].items():\n",
    "        if question['type'] == 'Multiple Choice':\n",
    "            if len(question['answerChoices']) != 4:\n",
    "                errors.append([subject, lesson_name, qid + ' mc error'])\n",
    "        if question['type'] == 'True or False':\n",
    "            if len(question['answerChoices']) != 2:\n",
    "                errors.append([subject, lesson_name, qid + ' tf error'])\n",
    "    return errors\n",
    "\n",
    "def record_validation_errors(dataset):\n",
    "    qs_removed = []\n",
    "    for subject, flexbook in dataset.items():\n",
    "        validator = jsonschema.Draft4Validator(schema)\n",
    "        for error in sorted(validator.iter_errors(flexbook), key=lambda x: x.absolute_path[0]):\n",
    "            lesson, quest, question_class, q_number = list(error.absolute_path)[:4]\n",
    "            problem_q_section = dataset[subject][lesson][quest][question_class]\n",
    "            if q_number in problem_q_section.keys():\n",
    "#                 print(dataset[subject][lesson][quest][question_class].pop(q_number))\n",
    "                qs_removed.append(dataset[subject][lesson][quest][question_class].pop(q_number))\n",
    "    return qs_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all validation test passed'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_dataset(ck12_combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_rem = record_validation_errors(ck12_combined_dataset)\n",
    "len(qs_rem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## remove recognition and localization errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "diagram_image_names = clean_list(recog_performed)\n",
    "\n",
    "rec_files = glob.glob(all_dir + '*/*')\n",
    "more_paths = glob.glob(all_dir + '*/*')\n",
    "pruned_paths = glob.glob(pruned_dir + '*/*')\n",
    "more_files = [fp.split('/')[-1] for fp in more_paths]\n",
    "pruned_files = [fp.split('/')[-1] for fp in pruned_paths]\n",
    "desc_paths = glob.glob(description_dir + '*/*')\n",
    "desc_files = [fp.split('/')[-1] for fp in desc_paths]\n",
    "\n",
    "\n",
    "pruned_nums = set([get_img_n(name) for name in pruned_files])\n",
    "all_nums = set([get_img_n(name) for name in more_files])\n",
    "rec_nums = set([get_img_n(name) for name in diagram_image_names])\n",
    "desc_nums = set([get_img_n(name) for name in desc_files])\n",
    "\n",
    "removed_images = all_nums.difference(pruned_nums.union(desc_nums))\n",
    "\n",
    "removed_image_names = []\n",
    "for img_n in removed_images:\n",
    "    for image_name in more_files:\n",
    "        if img_n == get_img_n(image_name):\n",
    "            removed_image_names.append(image_name)\n",
    "\n",
    "name_change_lookup = {}\n",
    "for image_name in more_files:\n",
    "    img_n = get_img_n(image_name)\n",
    "    for newer_name in pruned_files:\n",
    "        if img_n == get_img_n(newer_name) and newer_name != image_name:\n",
    "            name_change_lookup[image_name] = newer_name\n",
    "\n",
    "removed_image_names = sorted(removed_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "blacklisted_topics = ['periodic_table', 'em_spectrum', 'hydrocarbons', 'geologic_time'] + ['lewis_dot_idapgrams', 'circuits']  # correct this mispelling in future round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(removed_image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Add image annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagram</th>\n",
       "      <th>rectangle</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>assignment_id</th>\n",
       "      <th>worker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parts_cell_1182.png</td>\n",
       "      <td>[[283, 192], [447, 238]]</td>\n",
       "      <td>3SA4EMRVJV39U1MGLCYP6KPFULH0PX</td>\n",
       "      <td>3BDCF01OGXVJNV1XRULS5F5Z4B6LYG</td>\n",
       "      <td>A1017VP86SLXRB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               diagram                 rectangle  \\\n",
       "0  parts_cell_1182.png  [[283, 192], [447, 238]]   \n",
       "\n",
       "                           hit_id                   assignment_id  \\\n",
       "0  3SA4EMRVJV39U1MGLCYP6KPFULH0PX  3BDCF01OGXVJNV1XRULS5F5Z4B6LYG   \n",
       "\n",
       "        worker_id  \n",
       "0  A1017VP86SLXRB  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_res_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_anno = clean_list(os.path.join(turk_proc_dir, box_loc_joined))\n",
    "loc_anno_images = [fig.split('.json')[0]  for fig in loc_anno]\n",
    "keep_figures = [fig for fig in loc_anno_images if fig not in removed_image_names]\n",
    "\n",
    "loc_box_path = os.path.join(turk_proc_dir, box_loc_joined)\n",
    "\n",
    "diag_loc_annotations = {}\n",
    "for diagram_name in keep_figures:\n",
    "    anno_file_path = os.path.join(loc_box_path, diagram_name + '.json')\n",
    "    if not os.path.exists(anno_file_path):\n",
    "        diagram_name = diagram_name.replace('optics_rays', 'optics_ray_diagrams')\n",
    "        anno_file_path = os.path.join(loc_box_path, diagram_name  + '.json')\n",
    "    with open(anno_file_path, 'r') as f:\n",
    "        diag_loc_annotations[diagram_name] = json.load(f)\n",
    "\n",
    "combined_master_file_list = pruned_files + desc_files\n",
    "combined_master_file_list_whitelisted = [file for file in combined_master_file_list if file in keep_figures]\n",
    "files_still_needing_localisation = sorted(list(set(combined_master_file_list).difference(set(diag_loc_annotations))))\n",
    "len(files_still_needing_localisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def most_common_strict(image_response):\n",
    "    \"\"\"\n",
    "    returns the consensus response of the three raw response strings for a given image\n",
    "    \"\"\"\n",
    "    most_common = image_response[1]['raw_text'].mode()\n",
    "    if most_common.empty:\n",
    "        most_common = 'nonconsensus'\n",
    "        noncon.append(image_response[1]['raw_text'])\n",
    "    else:\n",
    "        most_common = most_common.values[0]\n",
    "    return most_common\n",
    "\n",
    "def most_common_lax(image_response, strings_denoting_missing_image=[]):\n",
    "    \"\"\"\n",
    "    returns the consensus response after stripping white space and converting the reponses to lower case\n",
    "    \"\"\"\n",
    "    simple_sanitizer = lambda x : x.lower().strip().lstrip()\n",
    "    ind_responses = image_response[1]['raw_text'].values\n",
    "    probobly_blanks = [response for response in ind_responses if response in strings_denoting_missing_image]\n",
    "    if probobly_blanks:\n",
    "        return 'skip'\n",
    "    most_common = image_response[1]['raw_text'].apply(simple_sanitizer).mode()\n",
    "    if most_common.empty:\n",
    "        most_common = 'no consensus'\n",
    "        noncon[image_response[0][0]].extend(image_response[1]['raw_text'])\n",
    "    else:\n",
    "        most_common = most_common.values[0]\n",
    "    return most_common\n",
    "\n",
    "def find_transcriptions_matches(batch_results_df, response_matcher):\n",
    "    \"\"\"\n",
    "    returns a pandas series with the consunsus response for each image\n",
    "    \"\"\"\n",
    "    agreed_responses = pd.DataFrame()\n",
    "    for image_response in batch_results_df.groupby(['diagram', 'box_diag_idx']):\n",
    "        diagram_and_idx = image_response[0]\n",
    "        most_common = response_matcher(image_response, strings_denoting_missing_image=[])\n",
    "        if most_common == 'skip':\n",
    "            continue\n",
    "        this_row = pd.DataFrame(list(diagram_and_idx) + [most_common, image_response[1]['rectangle'].iloc[0], image_response[1]['assignment_id'].iloc[0]]).T\n",
    "        agreed_responses = pd.concat([agreed_responses, this_row])\n",
    "        # The reindex below is needed to match the original df index after the groupby operation\n",
    "    agreed_responses.columns = ['diagram', 'box_diag_idx', 'consensus_res', 'rectangle', 'assignment_id']\n",
    "    return agreed_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2190"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recog_performed_on = set(pd.unique(recog_res_df['diagram']).tolist())\n",
    "len(recog_performed_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "files_still_needing_recognition = sorted(list(set(pruned_files).difference(set(recog_performed_on))))\n",
    "print(len(files_still_needing_recognition))\n",
    "file_with_loc_no_recog = set(files_still_needing_recognition).difference(files_still_needing_localisation)\n",
    "print(len(file_with_loc_no_recog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "noncon = defaultdict(list)\n",
    "transcription_results_lax = find_transcriptions_matches(recog_res_df, most_common_lax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "noncon_entries = [entries for entries in noncon.values()]\n",
    "flattened_noncon = [item for sublist in noncon_entries for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "curated_no_image_strings = set(['*no image showing*', '', ' ', 'NA', '?', 'na', '0', 'No image found', 'blank', 'Nothing showing', \"where is the images , i can't see anything\", 'NO IMAGE', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "non_blank_no_consensus = {d_name: rec_res for d_name, rec_res in noncon.items() if not curated_no_image_strings.intersection(set(rec_res))}\n",
    "blank_no_consensus = {d_name: rec_res for d_name, rec_res in noncon.items() if curated_no_image_strings.intersection(set(rec_res))}\n",
    "print(len(non_blank_no_consensus))\n",
    "print(len(blank_no_consensus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "flattened_noncon_no_blank = [item for sublist in non_blank_no_consensus.values() for item in sublist]\n",
    "build_diagram_rec_corpus  = [words.split() for words in transcription_results_lax['consensus_res'].values.tolist()]\n",
    "diagram_rec_corpus = set([item.lower().strip() for sublist in build_diagram_rec_corpus for item in sublist if item.isalpha() and len(item) > 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# strings_denoting_missing_image = list(pd.Series(flattened_noncon).value_counts()[:20].index)\n",
    "# Image.open('../ai2-vision-textbook-dataset/diagrams/turk_data/optics_ray_diagrams_9170.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4073"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diagram_rec_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Integrate diagram questions and descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## match diagram topics to lessons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "first need to match diagram topics to flexbook lessons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def make_topic_matches(topic_list, combined_topics):\n",
    "    topic_matches = {}\n",
    "    for diagram_topic in topic_list:\n",
    "        topic_matches[diagram_topic] = []\n",
    "        for terms in topic_term_match[diagram_topic]:\n",
    "            lev_dist_threshed = [topic for topic in combined_topics.keys() if fuzz.ratio(topic, terms) > 85]\n",
    "            topic_matches[diagram_topic] += lev_dist_threshed\n",
    "        if not topic_matches[diagram_topic]:\n",
    "                for terms in topic_term_match[diagram_topic]:\n",
    "                    lev_dist_threshed = [topic for topic in combined_topics.keys() if fuzz.token_set_ratio(topic, terms) > 80]\n",
    "                    topic_matches[diagram_topic] += lev_dist_threshed\n",
    "    return topic_matches\n",
    "\n",
    "def make_lesson_matches(ck12_dataset, diagram_topic_name, topic_matches):\n",
    "    lesson_matches = defaultdict(list)\n",
    "    lessons_seen = set()\n",
    "    content_topics =  topic_matches[diagram_topic_name]\n",
    "    for topic in sorted(content_topics):\n",
    "        associated_lesson =combined_topics[topic]['lesson']\n",
    "        if associated_lesson not in lessons_seen:\n",
    "            lessons_seen.add(associated_lesson)\n",
    "            lesson_matches[diagram_topic_name].append(associated_lesson)\n",
    "    return dict(lesson_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The pruned directory is the tqa 0.91 set assmbled by Ani on Sept 27th. It should be treated as definitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "diagram_topic_list = clean_list(pruned_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "es_lesson_names = [item for sublist in [val['topics'].keys() for val in ck12_combined_dataset['earth-science'].values()] for item in sublist]\n",
    "ps_lesson_names = [item for sublist in [val['topics'].keys() for val in ck12_combined_dataset['physical-science'].values()] for item in sublist]\n",
    "ls_lesson_names = [item for sublist in [val['topics'].keys() for val in ck12_combined_dataset['life-science'].values()] for item in sublist]\n",
    "\n",
    "combined_lessons = es_lesson_names + ps_lesson_names + ls_lesson_names\n",
    "topic_series = pd.Series(combined_lessons).value_counts()\n",
    "# the 17 here found by inspection- any \"topic\" appearing many times is something general like review, vocab, etc\n",
    "topics_to_remove = list(topic_series[:17].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "combined_topics = defaultdict(dict)\n",
    "for subject, book in ck12_combined_dataset.items():\n",
    "    for lesson, material in book.items():\n",
    "        for topic, text in material['topics'].items():\n",
    "            if topic in topics_to_remove:\n",
    "                continue\n",
    "            combined_topics[topic.lower()]['lesson'] = lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "topic_matches = make_topic_matches(diagram_topic_list, combined_topics)\n",
    "missing= []\n",
    "for k, v in topic_matches.items():\n",
    "    if not v:\n",
    "        missing.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "matching_lessons = {}\n",
    "for topic in diagram_topic_list:\n",
    "    matched_lessons = make_lesson_matches(ck12_combined_dataset, topic, topic_matches)\n",
    "    matching_lessons.update(matched_lessons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diagram_lesson_lookup = {}\n",
    "for d_topic, lessons in matching_lessons.items():\n",
    "    diagram_lesson_lookup[d_topic] = sorted(lessons)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#manually correct name changes made since diagrams were assembled\n",
    "diagram_lesson_lookup['lewis_dot_diagrams'] = diagram_lesson_lookup['lewis_dots']\n",
    "diagram_lesson_lookup['optics_ray_diagrams'] = diagram_lesson_lookup['optics_rays']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "lessons_seen = []\n",
    "dupe_lessons = []\n",
    "for k, v in diagram_lesson_lookup.items():\n",
    "    if v not in lessons_seen:\n",
    "        lessons_seen.append(v)\n",
    "    else:\n",
    "        dupe_lessons.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dupe_topics = defaultdict(list)\n",
    "for k, v in diagram_lesson_lookup.items():\n",
    "    if v in dupe_lessons:\n",
    "        dupe_topics[v].append(k)\n",
    "# dupe_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acid_rain_formation\n",
      "['22.2 Effects of Air Pollution']\n",
      "\n",
      "aquifers\n",
      "['13.3 Groundwater']\n",
      "\n",
      "atomic_mass_number\n",
      "['5.1 Inside the Atom', 'atomic number', 'matter mass and volume']\n",
      "\n",
      "atomic_structure\n",
      "['5.1 Inside the Atom']\n",
      "\n",
      "biomes\n",
      "['climate zones and biomes']\n",
      "\n",
      "blastocyst\n",
      "['22.3 Reproduction and Life Stages']\n",
      "\n",
      "cell_division\n",
      "['5.1 Cell Division']\n",
      "\n",
      "cellular_respiration\n",
      "['9.4 Biochemical Reactions']\n",
      "\n",
      "chemical_bonding_covalent\n",
      "['7.3 Covalent Bonds']\n",
      "\n",
      "chemical_bonding_ionic\n",
      "['7.2 Ionic Bonds']\n",
      "\n",
      "circuits\n",
      "['23.3 Electric Circuits']\n",
      "\n",
      "continental_drift\n",
      "['6.2 Continental Drift']\n",
      "\n",
      "convection_of_air\n",
      "['15.2 Energy in the Atmosphere']\n",
      "\n",
      "cycle_carbon\n",
      "['18.2 Cycles of Matter']\n",
      "\n",
      "cycle_nitrogen\n",
      "['18.2 Cycles of Matter']\n",
      "\n",
      "cycle_rock\n",
      "['4.1 Types of Rocks', 'rocks and processes of the rock cycle']\n",
      "\n",
      "cycle_water\n",
      "['24.2 Cycles of Matter']\n",
      "\n",
      "dna\n",
      "['nucleic acid classification']\n",
      "\n",
      "earth_day_night\n",
      "['rotation of earth']\n",
      "\n",
      "earth_eclipses\n",
      "['24.4 The Sun and the EarthMoon System']\n",
      "\n",
      "earth_magnetic_field\n",
      "['earth as a magnet']\n",
      "\n",
      "earth_moon_phases\n",
      "['24.4 The Sun and the EarthMoon System']\n",
      "\n",
      "earth_parts\n",
      "['6.1 Inside Earth']\n",
      "\n",
      "earth_poles\n",
      "['24.1 Planet Earth']\n",
      "\n",
      "electromagnetism\n",
      "['25.2 Using Electromagnetism']\n",
      "\n",
      "em_spectrum\n",
      "['15.2 Energy in the Atmosphere', '21.3 The Electromagnetic Spectrum', '23.1 Telescopes', 'electromagnetic spectrum', 'radio waves']\n",
      "\n",
      "erosion\n",
      "['10.1 Erosion and Deposition by Flowing Water', '10.2 Erosion and Deposition by Waves', '10.3 Erosion and Deposition by Wind', '10.4 Erosion and Deposition by Glaciers', '19.1 Loss of Soil', 'avoiding soil loss', 'landforms from groundwater erosion and deposition', 'rocks and processes of the rock cycle', 'soil erosion']\n",
      "\n",
      "eukaryotic_cell_cycles\n",
      "['5.1 Cell Division']\n",
      "\n",
      "evaporation_and_sublimation\n",
      "['4.3 Changes of State']\n",
      "\n",
      "faults\n",
      "['7.1 Stress in Earths Crust']\n",
      "\n",
      "food_chains_webs\n",
      "['24.1 Flow of Energy']\n",
      "\n",
      "fossils\n",
      "['11.1 Fossils']\n",
      "\n",
      "fungi_reproduction\n",
      "['9.2 Fungi']\n",
      "\n",
      "geologic_time\n",
      "['7.4 History of Life on Earth']\n",
      "\n",
      "glaciers\n",
      "['10.4 Erosion and Deposition by Glaciers', 'glaciers']\n",
      "\n",
      "greenhouse_effect\n",
      "['15.2 Energy in the Atmosphere']\n",
      "\n",
      "hair_follicles\n",
      "['16.2 The Integumentary System']\n",
      "\n",
      "human_system_circulatory\n",
      "['18.1 Overview of the Cardiovascular System']\n",
      "\n",
      "human_system_digestive\n",
      "['17.3 The Digestive System']\n",
      "\n",
      "human_system_ear\n",
      "['20.2 The Senses']\n",
      "\n",
      "human_system_excretory\n",
      "['excretion']\n",
      "\n",
      "human_system_eye\n",
      "['22.3 Vision']\n",
      "\n",
      "human_system_immune\n",
      "['21.4 Immune System Defenses']\n",
      "\n",
      "human_system_muscular\n",
      "['16.4 The Muscular System']\n",
      "\n",
      "human_system_nervous\n",
      "['20.1 The Nervous System', 'central nervous system', 'diseases of the nervous system', 'injuries of the nervous system', 'keeping the nervous system healthy', 'nervous system', 'peripheral nervous system']\n",
      "\n",
      "human_system_reproductory\n",
      "['22.1 Male Reproductive System', '22.2 Female Reproductive System', '22.4 Reproductive System Health', 'female reproductive system', 'male reproductive system', 'reproductive system health']\n",
      "\n",
      "human_system_respiratory\n",
      "['19.1 The Respiratory System', 'respiratory system diseases', 'respiratory system health', 'respiratory system organs']\n",
      "\n",
      "hydrocarbons\n",
      "['9.2 Hydrocarbons', 'combustion reactions', 'hydrocarbons', 'saturated hydrocarbons', 'unsaturated hydrocarbons']\n",
      "\n",
      "isotopes\n",
      "['5.1 Inside the Atom']\n",
      "\n",
      "layers_of_atmosphere\n",
      "['15.3 Layers of the Atmosphere']\n",
      "\n",
      "lewis_dots\n",
      "['7.1 Introduction to Chemical Bonds']\n",
      "\n",
      "life_cycles\n",
      "['12.4 Insects and Other Arthropods']\n",
      "\n",
      "muscle_fiber\n",
      "['16.4 The Muscular System', 'muscles and exercise']\n",
      "\n",
      "nuclear_energy\n",
      "['11.3 Nuclear Energy']\n",
      "\n",
      "ocean_currents\n",
      "['14.2 Ocean Movements']\n",
      "\n",
      "ocean_waves\n",
      "['14.2 Ocean Movements', '19.1 Characteristics of Waves', 'gamma rays', 'longitudinal wave', 'seismic waves']\n",
      "\n",
      "ocean_zones\n",
      "['14.1 Introduction to the Oceans']\n",
      "\n",
      "optics_lense_types\n",
      "['22.2 Optics']\n",
      "\n",
      "optics_rays\n",
      "['22.2 Optics']\n",
      "\n",
      "optics_reflection\n",
      "['22.2 Optics']\n",
      "\n",
      "optics_refraction\n",
      "['22.2 Optics']\n",
      "\n",
      "ozone_formation\n",
      "['22.1 Air Pollution']\n",
      "\n",
      "parts_cell\n",
      "['3.2 Cell Structures', '4.1 Transport', 'cell transport']\n",
      "\n",
      "parts_chordate_body\n",
      "['12.5 Echinoderms and Invertebrate Chordates', 'chordates']\n",
      "\n",
      "parts_fish\n",
      "['13.2 Fish']\n",
      "\n",
      "parts_flower\n",
      "['10.2 Evolution and Classification of Plants']\n",
      "\n",
      "parts_leaf\n",
      "['10.1 Introduction to Plants']\n",
      "\n",
      "parts_microscope\n",
      "['1.4 The Microscope', 'microscopes', 'optical instruments']\n",
      "\n",
      "parts_neuron\n",
      "['20.1 The Nervous System']\n",
      "\n",
      "parts_ocean_floor\n",
      "['14.3 The Ocean Floor']\n",
      "\n",
      "parts_plant\n",
      "['10.1 Introduction to Plants', '10.2 Evolution and Classification of Plants', '10.3 Plant Responses and Special Adaptations', '14.2 Mammals', '5.2 Nonrenewable Energy Resources', '5.3 Renewable Energy Resources', '6.2 Continental Drift', '9.1 Weathering', 'chemical weathering', 'electrical grid', 'fungi classification', 'nonvascular plants', 'reproduction in seedless plants', 'seeds and seed dispersal', 'symbiotic relationships of fungi', 'types of marine organisms', 'vascular seedless plants']\n",
      "\n",
      "parts_seed\n",
      "['10.2 Evolution and Classification of Plants']\n",
      "\n",
      "parts_skeleton\n",
      "['16.3 The Skeletal System']\n",
      "\n",
      "parts_telescope\n",
      "['22.2 Optics', 'optical instruments']\n",
      "\n",
      "parts_worm\n",
      "['12.2 Flatworms and Roundworms']\n",
      "\n",
      "periodic_table\n",
      "['6.1 How Elements Are Organized']\n",
      "\n",
      "phagocytosis\n",
      "['21.3 First Two Lines of Defense']\n",
      "\n",
      "photosynthesis\n",
      "['4.2 Photosynthesis']\n",
      "\n",
      "protozoa\n",
      "['9.1 Protists']\n",
      "\n",
      "radioactive_decay\n",
      "['radioactive decay as a measure of age']\n",
      "\n",
      "rain_shadow\n",
      "['17.1 Climate and Its Causes']\n",
      "\n",
      "seafloor_spreading\n",
      "['6.3 Seafloor Spreading']\n",
      "\n",
      "seasons\n",
      "['24.1 Planet Earth']\n",
      "\n",
      "seismic_waves\n",
      "['7.2 Nature of Earthquakes']\n",
      "\n",
      "simple_machines\n",
      "['16.3 Simple Machines']\n",
      "\n",
      "skin_cross_section\n",
      "['16.2 The Integumentary System']\n",
      "\n",
      "soil_horizons\n",
      "['9.2 Soils', 'processes of the water cycle']\n",
      "\n",
      "solar_system\n",
      "['25.1 Introduction to the Solar System']\n",
      "\n",
      "state_change\n",
      "['changes of state']\n",
      "\n",
      "states_of_matter\n",
      "['4.1 Solids Liquids Gases and Plasmas', 'kinetic theory of matter', 'solutions', 'states of water']\n",
      "\n",
      "stratigraphy\n",
      "['11.2 Relative Ages of Rocks']\n",
      "\n",
      "sun_layers\n",
      "['24.3 The Sun']\n",
      "\n",
      "tectonic_plates\n",
      "['6.4 Theory of Plate Tectonics']\n",
      "\n",
      "tectonic_plates_motion\n",
      "['6.4 Theory of Plate Tectonics', 'venus']\n",
      "\n",
      "tides\n",
      "['14.2 Ocean Movements']\n",
      "\n",
      "types_cells\n",
      "['cell biology']\n",
      "\n",
      "types_clouds\n",
      "['clouds']\n",
      "\n",
      "types_leaves\n",
      "['10.1 Introduction to Plants']\n",
      "\n",
      "velocity_time_graphs\n",
      "['12.3 Acceleration']\n",
      "\n",
      "volcanoes\n",
      "['8.3 Types of Volcanoes']\n",
      "\n",
      "waves\n",
      "['19.2 Measuring Waves']\n",
      "\n",
      "waves_interactions_interference\n",
      "['19.3 Wave Interactions and Interference']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len(diagram_lesson_lookup.keys())\n",
    "\n",
    "len(set(diagram_lesson_lookup.values()))\n",
    "\n",
    "for k, v in sorted(matching_lessons.items()):\n",
    "    print(k)\n",
    "    print(sorted(v))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# pprint.pprint(dict(dupe_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## merge questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dq_image_folder = 'diagram-question-images/'\n",
    "td_image_folder = 'diagram-teaching-images/'\n",
    "\n",
    "def make_question_entry(qdf_row):\n",
    "    ask = qdf_row[qdf_row.index == '03_write_question'].values[0]\n",
    "    answer = qdf_row[qdf_row.index == '04_write_right_answer'].values[0]\n",
    "    wrong_answers = qdf_row[qdf_row.index == 'wac_list'].values[0]\n",
    "    q_topic = qdf_row[qdf_row.index == 'lesson_assigned_to'].values[0]\n",
    "    image_uri = qdf_row[qdf_row.index == 's3_uri'].values[0]\n",
    "    image_name = qdf_row[qdf_row.index == 'diagram'].values[0]\n",
    "    \n",
    "    def make_answer_choices(answer_choices):\n",
    "        build_answer_choices = {}\n",
    "        letter_options = list('abcd')\n",
    "        random.shuffle(answer_choices)\n",
    "        for idx, answer_choice in enumerate(answer_choices):\n",
    "            answer_choice_dict = {\n",
    "                \"idStructural\": letter_options[idx] + '.',\n",
    "                \"rawText\": answer_choice,\n",
    "                \"processedText\": answer_choice\n",
    "            }\n",
    "            build_answer_choices[letter_options[idx]] = answer_choice_dict\n",
    "        return build_answer_choices\n",
    "    a_choices = make_answer_choices(wrong_answers + [answer])\n",
    "    single_q_dict = {\n",
    "        \"id\": 'q',\n",
    "        \"type\": \n",
    "            \"Diagram Multiple Choice\",\n",
    "        \"beingAsked\": {\n",
    "            \"rawText\": ask,\n",
    "            \"processedText\": ask.encode('ascii', 'ignore').decode('utf-8')\n",
    "        },\n",
    "        \"correctAnswer\": {\n",
    "            \"rawText\": answer,\n",
    "            \"processedText\": answer.encode('ascii', 'ignore').decode('utf-8')\n",
    "        },\n",
    "        \"answerChoices\": a_choices,\n",
    "        \"imageUri\": image_uri,\n",
    "        \"imageName\": image_name\n",
    "    }\n",
    "    build_questions[q_topic].append(single_q_dict)\n",
    "    \n",
    "    \n",
    "def refine_question_formats(raw_questions):\n",
    "    reformatted_dq_ds = {}\n",
    "    for topic, topic_questions in raw_questions.items():\n",
    "        reformatted_topic = {topic: {'questions': {'diagramQuestions': {}}}}\n",
    "        reformatted_questions = {}\n",
    "        for idx, question in enumerate(topic_questions):\n",
    "            question = deepcopy(question)\n",
    "            question['id'] += str(idx + 1).zfill(4)\n",
    "            reformatted_questions[question['id']] = question\n",
    "        reformatted_topic[topic]['questions']['diagramQuestions'] = reformatted_questions\n",
    "        reformatted_dq_ds.update(reformatted_topic)\n",
    "    return reformatted_dq_ds\n",
    "\n",
    "s3_base = 'https://s3.amazonaws.com/ai2-vision-textbook-dataset/diagrams/' + dq_image_folder\n",
    "s3_base_descriptions = 'https://s3.amazonaws.com/ai2-vision-textbook-dataset/diagrams/' + td_image_folder\n",
    "\n",
    "def make_image_link(old_url, s3_base=s3_base):\n",
    "    image_name = old_url.split('/')[-1]\n",
    "    new_url = s3_base + image_name\n",
    "    return new_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dr_proc_df['s3_uri'] = dr_proc_df['reference_id'].apply(make_image_link)\n",
    "dr_proc_df['lesson_assigned_to'] = dr_proc_df['topic'].apply(lambda x: diagram_lesson_lookup[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "build_questions = defaultdict(list)\n",
    "_ = dr_proc_df.apply(make_question_entry, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "refined_questions = refine_question_formats(build_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for subject, lessons in ck12_combined_dataset.items():\n",
    "    for l_name, lesson in lessons.items():\n",
    "        if l_name in refined_questions.keys():        \n",
    "            lesson['questions']['diagramQuestions'] = refined_questions[l_name]['questions']['diagramQuestions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['diagramQuestions'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_questions = dict(refine_question_formats(build_questions))\n",
    "\n",
    "refined_questions['10.4 Erosion and Deposition by Glaciers']['questions'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "refined_questions['10.4 Erosion and Deposition by Glaciers']\n",
    "\n",
    "len(ck12_combined_dataset['earth-science']['10.4 Erosion and Deposition by Glaciers']['questions']['diagramQuestions'])\n",
    "\n",
    "len(ck12_combined_dataset['earth-science']['10.4 Erosion and Deposition by Glaciers']['questions']['nonDiagramQuestions'])\n",
    "\n",
    "val_counts=dr_proc_df['lesson_assigned_to'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.1 Introduction to Plants                     1146\n",
       "24.1 Flow of Energy                             1006\n",
       "3.2 Cell Structures                              916\n",
       "12.4 Insects and Other Arthropods                719\n",
       "17.3 The Digestive System                        569\n",
       "24.4 The Sun and the EarthMoon System            389\n",
       "24.1 Planet Earth                                361\n",
       "6.1 Inside Earth                                 347\n",
       "20.1 The Nervous System                          337\n",
       "19.1 The Respiratory System                      291\n",
       "10.2 Evolution and Classification of Plants      281\n",
       "22.3 Vision                                      267\n",
       "8.3 Types of Volcanoes                           213\n",
       "25.1 Introduction to the Solar System            197\n",
       "22.2 Optics                                      195\n",
       "11.3 Nuclear Energy                              192\n",
       "18.1 Overview of the Cardiovascular System       181\n",
       "4.2 Photosynthesis                               177\n",
       "14.2 Ocean Movements                             172\n",
       "16.2 The Integumentary System                    168\n",
       "22.1 Male Reproductive System                    165\n",
       "5.1 Inside the Atom                              164\n",
       "23.3 Electric Circuits                           163\n",
       "16.4 The Muscular System                         147\n",
       "9.1 Protists                                     145\n",
       "1.4 The Microscope                               136\n",
       "6.4 Theory of Plate Tectonics                    120\n",
       "24.2 Cycles of Matter                            120\n",
       "5.1 Cell Division                                117\n",
       "excretion                                        111\n",
       "                                                ... \n",
       "6.2 Continental Drift                             63\n",
       "nucleic acid classification                       62\n",
       "21.4 Immune System Defenses                       60\n",
       "17.1 Climate and Its Causes                       59\n",
       "7.2 Nature of Earthquakes                         58\n",
       "14.1 Introduction to the Oceans                   54\n",
       "22.3 Reproduction and Life Stages                 53\n",
       "21.3 First Two Lines of Defense                   53\n",
       "15.3 Layers of the Atmosphere                     53\n",
       "7.4 History of Life on Earth                      50\n",
       "cell biology                                      49\n",
       "7.3 Covalent Bonds                                45\n",
       "12.3 Acceleration                                 45\n",
       "9.2 Hydrocarbons                                  44\n",
       "rotation of earth                                 44\n",
       "earth as a magnet                                 43\n",
       "9.4 Biochemical Reactions                         41\n",
       "7.1 Introduction to Chemical Bonds                39\n",
       "10.1 Erosion and Deposition by Flowing Water      38\n",
       "9.2 Fungi                                         37\n",
       "14.3 The Ocean Floor                              35\n",
       "25.2 Using Electromagnetism                       34\n",
       "10.4 Erosion and Deposition by Glaciers           33\n",
       "11.1 Fossils                                      28\n",
       "19.3 Wave Interactions and Interference           26\n",
       "22.2 Effects of Air Pollution                     25\n",
       "6.3 Seafloor Spreading                            25\n",
       "11.2 Relative Ages of Rocks                       24\n",
       "7.2 Ionic Bonds                                   21\n",
       "22.1 Air Pollution                                19\n",
       "Name: lesson_assigned_to, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## merge descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def make_description_entry(qdf_row):\n",
    "    description = qdf_row[qdf_row.index == 'Description'].values[0]\n",
    "    q_topic = qdf_row[qdf_row.index == 'lesson_assigned_to'].values[0]\n",
    "    image_uri = qdf_row[qdf_row.index == 's3_uri'].values[0]\n",
    "    image_name = qdf_row[qdf_row.index == 'diagram'].values[0]\n",
    "    image_key = image_name.replace('.png', '')\n",
    "    single_desc_dict = {\n",
    "        \"imageUri\": image_uri,\n",
    "        \"imageName\": image_name,\n",
    "        \"rawText\": description,\n",
    "        \"processedText\": description.encode('ascii', 'ignore').decode('utf-8')\n",
    "        }\n",
    "    if image_key not in build_descriptions[q_topic].keys():\n",
    "        build_descriptions[q_topic].update({image_key: single_desc_dict})\n",
    "    # I've found the longest description is usually best\n",
    "    elif len(single_desc_dict['processedText']) > len(build_descriptions[q_topic][image_key]['processedText']):\n",
    "        build_descriptions[q_topic].update({image_key: single_desc_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "ai2_written_df_completed['lesson_assigned_to'] = ai2_written_df_completed['topic'].apply(lambda x: diagram_lesson_lookup[x])\n",
    "ai2_written_df_completed['s3_uri'] = ai2_written_df_completed['Image Path'].apply(make_image_link)\n",
    "ai2_written_df_completed = ai2_written_df_completed.dropna()\n",
    "\n",
    "desc_df['topic'] = desc_df['diagram'].apply(lambda x: x.rsplit('_', maxsplit=1)[0])\n",
    "desc_df['lesson_assigned_to'] = desc_df['topic'].apply(lambda x: diagram_lesson_lookup[x])\n",
    "desc_df['s3_uri'] = desc_df['reference_id'].apply(make_image_link)\n",
    "desc_df['Description'] = desc_df['01_write_description']             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "build_descriptions = defaultdict(dict)\n",
    "_ = desc_df.apply(make_description_entry, axis=1)\n",
    "_ = ai2_written_df_completed.apply(make_description_entry, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# this adds the descriptions to the combined dataset\n",
    "for subject, lessons in ck12_combined_dataset.items():\n",
    "    for l_name, lesson in lessons.items():\n",
    "        if l_name in build_descriptions.keys():\n",
    "            lesson['instructionalDiagrams'] = build_descriptions[l_name]\n",
    "        else:\n",
    "            lesson['instructionalDiagrams'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(desc_df['lesson_assigned_to']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['5.1 Cell Division', '14.1 Introduction to the Oceans', '18.2 Cycles of Matter', '20.1 The Nervous System', 'nucleic acid classification', '9.2 Soils', '17.1 Climate and Its Causes', '12.5 Echinoderms and Invertebrate Chordates', '24.2 Cycles of Matter', 'radioactive decay as a measure of age', '8.3 Types of Volcanoes', '19.2 The Excretory System', '1.4 The Microscope', '16.3 The Skeletal System', '9.1 Protists', '14.3 The Ocean Floor', '4.1 Solids Liquids Gases and Plasmas', '6.1 Inside Earth', '10.1 Erosion and Deposition by Flowing Water', 'earth as a magnet', '16.3 Simple Machines', '10.2 Evolution and Classification of Plants', '9.2 Fungi', 'flatworms', '5.1 Inside the Atom', 'rotation of earth', '21.3 First Two Lines of Defense', 'nails and hair', '9.4 Biochemical Reactions', 'clouds', '10.4 Erosion and Deposition by Glaciers', '25.1 Introduction to the Solar System', 'blood vessels', '25.2 Using Electromagnetism', '19.1 The Respiratory System', 'faults', '13.2 Fish', '22.1 Male Reproductive System', '12.4 Insects and Other Arthropods', 'revolutions of earth', '24.1 Flow of Energy', '22.2 Optics', '21.4 Immune System Defenses', '7.4 History of Life on Earth', '22.3 Vision', '7.2 Nature of Earthquakes', '7.1 Introduction to Chemical Bonds', '24.3 The Sun', '6.4 Theory of Plate Tectonics', '6.2 Continental Drift', '6.1 How Elements Are Organized', '4.2 Photosynthesis', '3.1 Lifes Building Blocks', '19.2 Measuring Waves', '3.1 Properties of Matter', '24.4 The Sun and the EarthMoon System', '11.3 Nuclear Energy', '11.1 Fossils', '20.2 The Senses', '16.2 The Integumentary System', '15.2 Energy in the Atmosphere', '22.3 Reproduction and Life Stages', 'magnetic evidence for seafloor spreading', '17.3 The Digestive System', '4.1 Types of Rocks', '14.2 Ocean Movements', '10.1 Introduction to Plants', '11.2 Relative Ages of Rocks', '22.1 Air Pollution', '9.2 Hydrocarbons', 'climate zones and biomes', '23.3 Electric Circuits', '7.3 Covalent Bonds', '13.3 Groundwater', 'greenhouse effect', '15.3 Layers of the Atmosphere', '19.3 Wave Interactions and Interference', '22.2 Effects of Air Pollution', '7.2 Ionic Bonds', 'seasons', '4.3 Changes of State', '12.3 Acceleration', '3.2 Cell Structures', '16.4 The Muscular System'])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_descriptions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# with open(output_dir + 'ck12_dataset_beta_v4.json', 'w') as f:\n",
    "#     json.dump(ck12_combined_dataset, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# with open(output_dir + 'ck12_dataset_beta_v4.json', 'r') as f:\n",
    "#     ck12_combined_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Apply spelling and grammar fixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def check_mispelled(word):\n",
    "    return word and word.isalpha() and not (edict.check(word) or anglo_edict.check(word) or edict.check(word[0].upper() + word[1:]))\n",
    "\n",
    "def correct_spelling_error(misspelled_word, suggested_spellings):\n",
    "    highest_ratio = 0\n",
    "    closest_match = None\n",
    "    for word in suggested_spellings:\n",
    "        match_r = fuzz.ratio(misspelled_word, word)\n",
    "        if match_r >= highest_ratio and (word[0] == misspelled_word[0] or not check_mispelled(word[0] + misspelled_word)) and len(misspelled_word) <= len(word):\n",
    "            highest_ratio = match_r\n",
    "            closest_match = word\n",
    "            break\n",
    "    spell_changes[misspelled_word] = closest_match\n",
    "    return closest_match\n",
    "\n",
    "def apply_spelling_fix(orig_text):\n",
    "    orig_text_tokens = wordpunct_tokenize(orig_text)\n",
    "    processed_tokens = []\n",
    "    for token in orig_text_tokens:\n",
    "        norm_token = token.lower()\n",
    "        if len(norm_token) < 4:\n",
    "            processed_tokens.append(token)\n",
    "            continue\n",
    "        if check_mispelled(norm_token):\n",
    "            suggested_replacements = edict.suggest(token)\n",
    "            replacement_text = correct_spelling_error(norm_token, suggested_replacements)\n",
    "            if replacement_text:\n",
    "                if norm_token[0].isupper():\n",
    "                    replacement_text = upper(replacement_text[0]) + replaced_text[1:]\n",
    "                processed_tokens.append(replacement_text)\n",
    "            else:\n",
    "                processed_tokens.append(token)\n",
    "        else:\n",
    "            processed_tokens.append(token)\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "def diff_corrected_text(orig_text, corrected_text):\n",
    "    diff = dmp.diff_main(orig_text, corrected_text)\n",
    "    return HTML(dmp.diff_prettyHtml(diff))\n",
    "\n",
    "def specify_lesson_q_path(lesson):\n",
    "    pass\n",
    "    \n",
    "\n",
    "def apply_spelling_and_grammar_to_ds(ck12_ds):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dmp = diff_match_patch.diff_match_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ck12_spell_gramm_fix_test = deepcopy(ck12_combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "gram_checker = language_check.LanguageTool('en-US')\n",
    "gram_checker.disabled = set(['SENT_START_CONJUNCTIVE_LINKING_ADVERB_COMMA', 'POSSESSIVE_APOSTROPHE', 'A_PLURAL'])\n",
    "gram_checker.disable_spellchecking()\n",
    "\n",
    "punc_set_space = set([',', ':', ';', '/\"'])\n",
    "punc_set_nospace = set(['-', '\\'', '-', '?', '.', '!'])\n",
    "question_enders = set(['.', '?', ':'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#check descriptions\n",
    "spell_changes = {}\n",
    "unaltered_text = []\n",
    "replaced_text = []\n",
    "for lesson in list(ck12_spell_gramm_fix_test['life-science'].values()):\n",
    "    if lesson['instructionalDiagrams']:\n",
    "        for diagram, description in lesson['instructionalDiagrams'].items():\n",
    "            orig_text = description['processedText']\n",
    "            spell_fixed_text = apply_spelling_fix(orig_text)\n",
    "            for punc_char in punc_set_nospace:\n",
    "                spell_fixed_text = spell_fixed_text.replace(' ' + punc_char + ' ' , punc_char)\n",
    "            for punc_char in punc_set_space:\n",
    "                spell_fixed_text = spell_fixed_text.replace(' ' + punc_char + ' ' , punc_char + ' ')\n",
    "            gram_fixed = gram_checker.correct(spell_fixed_text)\n",
    "            if gram_fixed != orig_text:\n",
    "                unaltered_text.append(orig_text)\n",
    "                replaced_text.append(gram_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2603,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check diagram questions\n",
    "spell_changes = {}\n",
    "unaltered_text = []\n",
    "replaced_text = []\n",
    "for lesson in list(ck12_spell_gramm_fix_test['life-science'].values()):\n",
    "    if lesson['questions']['nonDiagramQuestions']:\n",
    "        for diagram, description in lesson['questions']['DiagramQuestions'].items():\n",
    "            orig_text = description['beingAsked']['processedText']\n",
    "            spell_fixed_text = apply_spelling_fix(orig_text)\n",
    "            gram_fixed = gram_checker.correct(spell_fixed_text)\n",
    "            for punc_char in punc_set_nospace:\n",
    "                gram_fixed = gram_fixed.replace(' ' + punc_char + ' ' , punc_char)\n",
    "                gram_fixed = gram_fixed.replace(' ' + punc_char, punc_char)\n",
    "            for punc_char in punc_set_space:\n",
    "                gram_fixed = gram_fixed.replace(' ' + punc_char + ' ' , punc_char + ' ')\n",
    "            if gram_fixed[-1] not in question_enders:\n",
    "                if gram_fixed.split()[0] in ['Identify', 'Name'] or '__' in gram_fixed:\n",
    "                    gram_fixed += '.'\n",
    "                else:\n",
    "                    gram_fixed += '?'\n",
    "            if gram_fixed != orig_text:\n",
    "                unaltered_text.append(orig_text)\n",
    "                replaced_text.append(gram_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "comp_text = list(zip(unaltered_text, replaced_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "print(len(spell_changes))\n",
    "print(len(comp_text))\n",
    "# spell_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The diagram shows the circulatory system. It is the system that circulates blood and lymph through the body consisting of the heart, blood vessels, blood, lymph, and the lymphatic vessels and glands. Arterial circulation is the part of your circulatory system that involves arteries, like the aorta and pulmonary arteries. Arteries are blood vessels that carry blood away from your heart. (The exception is the coronary arteries, which supply your heart muscle with oxygen-rich blood.) Venous circulation is the part of your circulatory system that involves veins, like the vena cavae and pulmonary veins. Veins are blood vessels that carry blood to your heart. Veins have thinner walls than arteries.\n",
      "\n",
      "The diagram shows the circulatory system. It is the system that circulates blood and lymph through the body consisting of the heart, blood vessels, blood, lymph, and the lymphatic vessels and glands. Arterial circulation is the part of your circulatory system that involves arteries, like the aorta and pulmonary arteries. Arteries are blood vessels that carry blood away from your heart.(The exception is the coronary arteries, which supply your heart muscle with oxygen-rich blood.) Venous circulation is the part of your circulatory system that involves veins, like the vena cavae and pulmonary veins. Veins are blood vessels that carry blood to your heart. Veins have thinner walls than arteries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span>The diagram shows the circulatory system. It is the system that circulates blood and lymph through the body consisting of the heart, blood vessels, blood, lymph, and the lymphatic vessels and glands. Arterial circulation is the part of your circulatory system that involves arteries, like the aorta and pulmonary arteries. Arteries are blood vessels that carry blood away from your heart.</span><del style=\"background:#ffe6e6;\"> </del><span>(The exception is the coronary arteries, which supply your heart muscle with oxygen-rich blood.) Venous circulation is the part of your circulatory system that involves veins, like the vena cavae and pulmonary veins. Veins are blood vessels that carry blood to your heart. Veins have thinner walls than arteries.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_idx = np.random.randint(len(comp_text))\n",
    "print(unaltered_text[rand_idx])\n",
    "print()\n",
    "print(replaced_text[rand_idx])\n",
    "diff_corrected_text(*comp_text[rand_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# with open(output_dir + 'ck12_dataset_beta_v4.json', 'r') as f:\n",
    "#     ck12_combined_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Topic key collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['physical-science', 'earth-science', 'life-science'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexbook_ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "build_website_lessons = [list(lesson.keys()) for lesson in lessons_ds.values()]\n",
    "website_lessons= sorted([item for sublist in build_website_lessons for item in sublist])\n",
    "\n",
    "build_flexbook_lessons = [list(lesson.keys()) for lesson in flexbook_ds.values()]\n",
    "flexbook_lessons= [item for sublist in build_flexbook_lessons for item in sublist]\n",
    "flexbook_lessons = sorted([lesson.split(maxsplit=1)[1].strip().lower() for lesson in flexbook_lessons])\n",
    "fbls = set(flexbook_lessons)\n",
    "wsls = set(website_lessons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flexbook_lessons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "print(len(flexbook_lessons))\n",
    "print(len(set(flexbook_lessons)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829\n",
      "829\n"
     ]
    }
   ],
   "source": [
    "print(len(website_lessons))\n",
    "print(len(set(website_lessons)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(website_lessons).union(set(flexbook_lessons)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refinements to make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "global ids\n",
    "\n",
    "make all abc questions upper/lower case\n",
    "\n",
    "add vocab defs\n",
    "\n",
    "punctuation/ text normalization\n",
    "\n",
    "maybe spell and grammar on entire set\n",
    "\n",
    "linking lessons\n",
    "\n",
    "image_uris now point to local dir instead of s3\n",
    "\n",
    "remove ck12 lesson numbers from keys and image names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(topics_to_remove) #specicied in match topics section above, explictly set here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structural_topics = ['Summary', 'Review', 'References', 'Explore More', 'Lesson Summary', 'Lesson Objectives', 'Points to Consider', 'Introduction',\n",
    "                    'Recall', 'Apply Concepts', 'Think Critically', 'Resources', 'Explore More II', 'Explore More I', 'Explore More III']\n",
    "\n",
    "vocab_topics = ['Lesson Vocabulary', 'Vocabulary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterate_over_all_material(complete_ds):\n",
    "    dq_gid = 0\n",
    "    ndq_gid = 0\n",
    "    for subject, lessons in complete_ds.items():\n",
    "        for lesson_name, lesson_content in lessons.items():\n",
    "            struct_topics = iterate_over_text(lesson_content['topics'])\n",
    "#             lesson_content['adjunctTopics'] = struct_topics\n",
    "            iterate_over_text_questions(lesson_content['questions']['nonDiagramQuestions'])\n",
    "            if lesson_content['instructionalDiagrams']:\n",
    "                if not lesson_content['questions']['diagramQuestions']:\n",
    "                    print(lesson_name + ' missing questions')\n",
    "                iterate_over_diagram_questions(lesson_content['questions']['diagramQuestions'])\n",
    "                iterate_over_diagram_descriptions(lesson_content['instructionalDiagrams'])\n",
    "            \n",
    "def iterate_over_text(topic_sections):\n",
    "    structural_content = {}\n",
    "    for topic, content in topic_sections.items():\n",
    "        if topic in vocab_topics:\n",
    "            add_defintions_to_vocab(content)\n",
    "        elif topic in structural_topics:\n",
    "            structural_content[topic] = content\n",
    "    return structural_content\n",
    "    \n",
    "def add_defintions_to_vocab(vocab_section):\n",
    "#     print('adding')\n",
    "    pass\n",
    "\n",
    "def iterate_over_text_questions(text_questions):\n",
    "        for qid, question in text_questions.items():\n",
    "            add_global_ids(question, 'text')\n",
    "            \n",
    "def iterate_over_diagram_questions(diagram_questions):\n",
    "        for qid, question in diagram_questions.items():\n",
    "            add_global_ids(question, 'diagram')\n",
    "            replace_uri_with_path(question, 'question_images')\n",
    "            if detect_abc_question(question):\n",
    "                standardize_abc_question(question)\n",
    "\n",
    "def iterate_over_diagram_descriptions(diagram_descriptions, description_path_prefix=None):\n",
    "    for diagram_name, diagram_content in diagram_descriptions.items():\n",
    "        replace_uri_with_path(diagram_content, 'teaching_images')\n",
    "    pass\n",
    "\n",
    "def add_global_ids(global_count, which_counter):\n",
    "#     print('add ids')\n",
    "    pass\n",
    "\n",
    "def detect_abc_question(question):\n",
    "    return False\n",
    "\n",
    "def standardize_abc_question(question):\n",
    "    pass\n",
    "\n",
    "def replace_uri_with_path(image_content, path_prefix):\n",
    "    pass\n",
    "#     image_content.pop('imageUri')\n",
    "#     image_content['imagePath'] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iterate_over_all_material(test_cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instructionalDiagrams', 'questions', 'topics', 'hidden', 'adjunctTopics'])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_cds['earth-science'].values())[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(test_cds['earth-science'].values())[0]['adjunctTopics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_cds = deepcopy(ck12_combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#             print(lesson_content['topics'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Splitting experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# flexbook_glossary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(list(diagram_lesson_lookup.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_lesson = ck12_combined_dataset['earth-science']['24.1 Planet Earth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pprint.pprint(test_lesson['instructionalDiagrams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This Diagram shows the Earth's rotation. Which is the amount of time that it takes to rotate once on its axis. This is, apparently, accomplished once a day  every 24 hours. However, there are actually two different kinds of rotation that need to be considered here. For one, theres the amount of time it take for the Earth to turn once on its axis so that it returns to the same orientation compared to the rest of the Universe. Then theres how long it takes for the Earth to turn so that the Sun returns to the same spot in the sky. Earth's rotation is slowing slightly with time; thus, a day was shorter in the past. This is due to the tidal effects the Moon has on Earth's rotation. Atomic clocks show that a modern-day is longer by about 1.7 milliseconds than a century ago, slowly increasing the rate at which UTC is adjusted by leap seconds.\""
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_lesson['instructionalDiagrams'].values())[0]['processedText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Earths Rotation', 'Earths Gravity', 'Earths Shape Size and Mass', 'Lesson Summary', 'Introduction', 'Lesson Objectives', 'Earths Magnetism', 'Recall', 'Points to Consider', 'Think Critically', 'Earths Revolution', 'Apply Concepts', 'Vocabulary', 'Earths Motions', 'Earths Day and Night', 'Earths Seasons'])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lesson['topics'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_vocab = test_lesson['topics']['Vocabulary']['content']['text'].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an imaginary line that runs from the North Pole to South Pole through the center of Earth \n",
      "\n",
      "highest level of organization in ecology that includes all the parts of Earth where life can be found and consists of all the worlds biomes, both terrestrial and aquatic \n",
      "\n",
      "As traditionally defined, force of attraction between two masses. \n",
      "\n",
      "one half of a sphere \n",
      "\n",
      "all the water on Earth \n",
      "\n",
      "Area around a magnet where it exerts magnetic force. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in test_vocab:\n",
    "    if word in flexbook_glossary:\n",
    "        print(flexbook_glossary[word])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# write_file('ck12_v4_5.json', ck12_combined_dataset, 'experimental_output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
