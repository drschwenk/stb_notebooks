{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Table of Contents\n",
    "* [move diagrams to 0.91](#move-diagrams-to-0.91)\n",
    "* [load all localization](#load-all-localization)\n",
    "* [load all recognition](#load-all-recognition)\n",
    "* [load diagram questions and descriptions](#load-diagram-questions-and-descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import itertools\n",
    "import math\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import pprint\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import io\n",
    "import sys\n",
    "import os\n",
    "from binascii import b2a_hex\n",
    "import base64\n",
    "from wand.image import Image as WImage\n",
    "from IPython.display import display\n",
    "import PIL.Image as Image\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "import os\n",
    "import jsonschema\n",
    "from pdfextraction.ck12_schema import ck12_schema as schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def write_file(filename, date, output_dir='output_data_from_nbs'):\n",
    "    with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "        json.dump(date, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def validate_schema(dataset_json):\n",
    "    errors = []\n",
    "    try:\n",
    "        validator = jsonschema.Draft4Validator(schema)\n",
    "        for error in sorted(validator.iter_errors(flexbook), key=lambda x: x.absolute_path[0]):\n",
    "            errors.append([error.message, list(error.absolute_path)[:4]])\n",
    "    except jsonschema.ValidationError as e:\n",
    "        errors.append(\"Error in schema --%s-\", e.message)\n",
    "    return errors\n",
    "\n",
    "def validate_dataset(dataset_json):\n",
    "    for subject, flexbook in dataset_json.items():\n",
    "        schema_errors = validate_schema(flexbook)\n",
    "        for lesson_name, lesson in flexbook.items():\n",
    "            ac_errors = check_ac_counts(lesson, subject, lesson_name)\n",
    "        all_errors = schema_errors + ac_errors\n",
    "        if not all_errors:\n",
    "            return 'all validation test passed'\n",
    "        else:\n",
    "            return all_errors\n",
    "\n",
    "def check_ac_counts(lesson_content, subject, lesson_name):\n",
    "    errors = []\n",
    "    for qid, question in lesson_content['questions']['nonDiagramQuestions'].items():\n",
    "        if question['type'] == 'Multiple Choice':\n",
    "            if len(question['answerChoices']) != 4:\n",
    "                errors.append([subject, lesson_name, qid + ' mc error'])\n",
    "        if question['type'] == 'True or False':\n",
    "            if len(question['answerChoices']) != 2:\n",
    "                errors.append([subject, lesson_name, qid + ' tf error'])\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# load text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "output_dir = 'output_data_from_nbs/'\n",
    "with open(output_dir + 'ck12_flexbook_only_beta_v3.json', 'r') as f:\n",
    "    flexbook_ds = json.load(f)\n",
    "with open(output_dir + 'ck12_lessons_only_beta_v3.json', 'r') as f:\n",
    "    lessons_ds = json.load(f)\n",
    "with open(output_dir + 'ck12_dataset_beta_v3.json', 'r') as f:\n",
    "    ck12_combined_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pat_str = \"(?:https?:\\/\\/(?:www\\.).*?\\s)\"\n",
    "web_link_patern=re.compile(pat_str)\n",
    "\n",
    "def clean_content_text(content_str, web_link_patern):\n",
    "    removed_links = web_link_patern.findall(content_str)\n",
    "    if not removed_links:\n",
    "        return '', ''\n",
    "    split_txt = web_link_patern.split(content_str)\n",
    "    cleaned_text = ' '.join([txt for txt in split_txt if txt])\n",
    "    return cleaned_text, [link.strip() for link in removed_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def extract_links(complete_ds):\n",
    "    for subject, lessons in complete_ds.items():\n",
    "        for lesson_title, lesson in lessons.items():\n",
    "            for topic, content in lesson['topics'].items():\n",
    "                content_str = content['content']['text']\n",
    "                new_text, links = clean_content_text(content_str, web_link_patern)\n",
    "                content['content']['mediaLinks'] = []\n",
    "                if links:\n",
    "                    content['content']['text'] = new_text\n",
    "                    content['content']['mediaLinks'].extend(links)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ck12_combined_dataset_cleaned = deepcopy(ck12_combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "extract_links(ck12_combined_dataset_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "write_file('ck12_dataset_v3_5.json', ck12_combined_dataset_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def record_validation_errors(dataset):\n",
    "    qs_removed = []\n",
    "    for subject, flexbook in dataset.items():\n",
    "        validator = jsonschema.Draft4Validator(schema)\n",
    "        for error in sorted(validator.iter_errors(flexbook), key=lambda x: x.absolute_path[0]):\n",
    "            lesson, quest, question_class, q_number = list(error.absolute_path)[:4]\n",
    "            problem_q_section = dataset[subject][lesson][quest][question_class]\n",
    "            if q_number in problem_q_section.keys():\n",
    "#                 print(dataset[subject][lesson][quest][question_class].pop(q_number))\n",
    "                qs_removed.append(dataset[subject][lesson][quest][question_class].pop(q_number))\n",
    "    return qs_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "qs_rem = record_validation_errors(ck12_combined_dataset_cleaned)\n",
    "len(qs_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all validation test passed'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_dataset(ck12_combined_dataset_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# move diagrams to 0.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def get_img_n(image_name):\n",
    "    return [re.findall(\"[0-9]+\", image_name)][0][0]\n",
    "\n",
    "def clean_list(dir_path):\n",
    "    hidden_removed = filter(lambda f: not f.startswith('.'), os.listdir(dir_path))\n",
    "    return [topic.replace('_diagram', '') for topic in hidden_removed]\n",
    "\n",
    "recog_performed = '/Users/schwenk/wrk/stb/diagram_questions/turk_processing/final_diagrams/'\n",
    "all_dir = '/Users/schwenk/wrk/stb/ai2-vision-textbook-dataset/diagrams/tqa_diagrams_v0.9/'\n",
    "pruned_dir = '/Users/schwenk/wrk/stb/ai2-vision-textbook-dataset/diagrams/dataset_Sep_27/tqa_diagrams_v0.9_question_images/'\n",
    "diagram_image_names = clean_list(recog_performed)\n",
    "\n",
    "rec_files = glob.glob(all_dir + '*/*')\n",
    "more_paths = glob.glob(all_dir + '*/*')\n",
    "pruned_paths = glob.glob(pruned_dir + '*/*')\n",
    "more_files = [fp.split('/')[-1] for fp in more_paths]\n",
    "pruned_files = [fp.split('/')[-1] for fp in pruned_paths]\n",
    "\n",
    "pruned_nums = set([get_img_n(name) for name in pruned_files])\n",
    "all_nums = set([get_img_n(name) for name in more_files])\n",
    "rec_nums = set([get_img_n(name) for name in diagram_image_names])\n",
    "\n",
    "removed_images = all_nums.difference(pruned_nums)\n",
    "\n",
    "removed_image_names = []\n",
    "for img_n in removed_images:\n",
    "    for image_name in more_files:\n",
    "        if img_n == get_img_n(image_name):\n",
    "            removed_image_names.append(image_name)\n",
    "\n",
    "name_change_lookup = {}\n",
    "for image_name in more_files:\n",
    "    img_n = get_img_n(image_name)\n",
    "    for newer_name in pruned_files:\n",
    "        if img_n == get_img_n(newer_name) and newer_name != image_name:\n",
    "            name_change_lookup[image_name] = newer_name\n",
    "\n",
    "removed_image_names = sorted(removed_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'electromagnetism_9087.png': 'em_spectrum_9087.png',\n",
       " 'lewis_dot_idagrams_9131.png': 'lewis_dot_diagrams_9131.png',\n",
       " 'lewis_dot_idagrams_9132.png': 'lewis_dot_diagrams_9132.png',\n",
       " 'lewis_dot_idagrams_9133.png': 'lewis_dot_diagrams_9133.png',\n",
       " 'lewis_dot_idagrams_9134.png': 'lewis_dot_diagrams_9134.png',\n",
       " 'lewis_dot_idagrams_9135.png': 'lewis_dot_diagrams_9135.png',\n",
       " 'lewis_dot_idagrams_9136.png': 'lewis_dot_diagrams_9136.png',\n",
       " 'lewis_dot_idagrams_9137.png': 'lewis_dot_diagrams_9137.png',\n",
       " 'lewis_dot_idagrams_9138.png': 'lewis_dot_diagrams_9138.png',\n",
       " 'lewis_dot_idagrams_9139.png': 'lewis_dot_diagrams_9139.png',\n",
       " 'lewis_dot_idagrams_9141.png': 'lewis_dot_diagrams_9141.png',\n",
       " 'lewis_dot_idagrams_9142.png': 'lewis_dot_diagrams_9142.png',\n",
       " 'lewis_dot_idagrams_9143.png': 'lewis_dot_diagrams_9143.png',\n",
       " 'lewis_dot_idagrams_9144.png': 'lewis_dot_diagrams_9144.png',\n",
       " 'lewis_dot_idagrams_9145.png': 'lewis_dot_diagrams_9145.png',\n",
       " 'lewis_dot_idagrams_9147.png': 'lewis_dot_diagrams_9147.png',\n",
       " 'lewis_dot_idagrams_9148.png': 'lewis_dot_diagrams_9148.png',\n",
       " 'lewis_dot_idagrams_9149.png': 'lewis_dot_diagrams_9149.png'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_change_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(removed_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "turk_proc_dir = '/Users/schwenk/wrk/stb/diagram_questions/turk_processing/'\n",
    "metadata_dir = turk_proc_dir + 'store_hit_results_metadata/'\n",
    "lc_results_dir = 'loc_group_3'\n",
    "box_choices_1_dir = 'final_text_boxes_fixed'\n",
    "box_choices_2_dir = 'final_text_boxes_pass_2'\n",
    "box_loc_joined = 'loc_annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "none_agree = 'no_turkers_agree_lookup.pkl'\n",
    "two_agree_lookup = 'two_turkers_agree_lookup.pkl'\n",
    "all_agree_lookup = 'user_diag_loopkup.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_res_df = pd.read_pickle(os.path.join(metadata_dir, lc_results_dir, 'complete_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagram</th>\n",
       "      <th>rectangle</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>assignment_id</th>\n",
       "      <th>worker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parts_cell_1182.png</td>\n",
       "      <td>[[283, 192], [447, 238]]</td>\n",
       "      <td>3SA4EMRVJV39U1MGLCYP6KPFULH0PX</td>\n",
       "      <td>3BDCF01OGXVJNV1XRULS5F5Z4B6LYG</td>\n",
       "      <td>A1017VP86SLXRB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               diagram                 rectangle  \\\n",
       "0  parts_cell_1182.png  [[283, 192], [447, 238]]   \n",
       "\n",
       "                           hit_id                   assignment_id  \\\n",
       "0  3SA4EMRVJV39U1MGLCYP6KPFULH0PX  3BDCF01OGXVJNV1XRULS5F5Z4B6LYG   \n",
       "\n",
       "        worker_id  \n",
       "0  A1017VP86SLXRB  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_res_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2307,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(loc_res_df['diagram']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(turk_proc_dir, all_agree_lookup), 'rb') as f:\n",
    "    box_ns = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_anno = clean_list(os.path.join(turk_proc_dir, box_loc_joined))\n",
    "loc_anno_images = [fig.split('.json')[0]  for fig in figures_with_locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_figures = [fig for fig in loc_anno_images if fig not in removed_image_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_box_path = os.path.join(turk_proc_dir, box_loc_joined)\n",
    "diag_loc_annotations = {}\n",
    "\n",
    "for diagram_name in keep_figures:\n",
    "    anno_file_path = os.path.join(loc_box_path, diagram_name + '.json')\n",
    "    if not os.path.exists(anno_file_path):\n",
    "#         print(diagram_name)\n",
    "        diagram_name = diagram_name.replace('optics_rays', 'optics_ray_diagrams')\n",
    "        anno_file_path = os.path.join(loc_box_path, diagram_name  + '.json')\n",
    "#         continue\n",
    "    with open(anno_file_path, 'r') as f:\n",
    "        diag_loc_annotations[diagram_name] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sorted(diag_loc_annotations)[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1935"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diag_loc_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_still_needing_localisation = sorted(list(set(pruned_files).difference(set(diag_loc_annotations))))\n",
    "len(files_still_needing_localisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recog_output = '/Users/schwenk/wrk/stb/diagram_questions/turk_processing/'\n",
    "recog_results_dir = 'group_latest_combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import mode\n",
    "noncon = []\n",
    "\n",
    "def most_common_strict(image_response):\n",
    "    \"\"\"\n",
    "    returns the consensus response of the three raw response strings for a given image\n",
    "    \"\"\"\n",
    "    most_common = image_response[1]['raw_text'].mode()\n",
    "    if most_common.empty:\n",
    "        most_common = 'nonconsensus'\n",
    "        noncon.append(image_response[1]['raw_text'])\n",
    "    else:\n",
    "        most_common = most_common.values[0]\n",
    "    return most_common\n",
    "\n",
    "def most_common_lax(image_response, strings_denoting_missing_image=[]):\n",
    "    \"\"\"\n",
    "    returns the consensus response after stripping white space and converting the reponses to lower case\n",
    "    \"\"\"\n",
    "    simple_sanitizer = lambda x : x.lower().strip().lstrip()\n",
    "    ind_responses = image_response[1]['raw_text'].values\n",
    "    probobly_blanks = [response for response in ind_responses if response in strings_denoting_missing_image]\n",
    "    if probobly_blanks:\n",
    "        return 'skip'\n",
    "    most_common = image_response[1]['raw_text'].apply(simple_sanitizer).mode()\n",
    "    if most_common.empty:\n",
    "        most_common = 'no consensus'\n",
    "        noncon.append(image_response[1]['raw_text'])\n",
    "    else:\n",
    "        most_common = most_common.values[0]\n",
    "    return most_common\n",
    "\n",
    "def find_transcriptions_matches(batch_results_df, response_matcher):\n",
    "    \"\"\"\n",
    "    returns a pandas series with the consunsus response for each image\n",
    "    \"\"\"\n",
    "    agreed_responses = pd.DataFrame()\n",
    "    for image_response in batch_results_df.groupby(['diagram', 'box_diag_idx']):\n",
    "        diagram_and_idx = image_response[0]\n",
    "        most_common = response_matcher(image_response, strings_denoting_missing_image=[])\n",
    "        if most_common == 'skip':\n",
    "            continue\n",
    "        this_row = pd.DataFrame(list(diagram_and_idx) + [most_common, image_response[1]['rectangle'].iloc[0], image_response[1]['assignment_id'].iloc[0]]).T\n",
    "        agreed_responses = pd.concat([agreed_responses, this_row])\n",
    "        # The reindex below is needed to match the original df index after the groupby operation\n",
    "    agreed_responses.columns = ['diagram', 'box_diag_idx', 'consensus_res', 'rectangle', 'assignment_id']\n",
    "    return agreed_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recog_res_df = pd.read_pickle(os.path.join(metadata_dir, recog_results_dir, 'recog_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recog_performed_on = set(pd.unique(recog_res_df['diagram']).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recog_performed_on_keep = [image for image in recog_performed_on if image in keep_figures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1915"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recog_performed_on_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_still_needing_recognition = sorted(list(set(pruned_files).difference(set(recog_performed_on_keep))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_with_loc_no_recog = set(files_still_needing_recognition).difference(files_still_needing_localisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file_with_loc_no_recog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transcription_results_lax = find_transcriptions_matches(recog_res_df, most_common_lax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncon_entries = [entries.values.tolist() for entries in noncon]\n",
    "flattened_noncon = [item for sublist in noncon_entries for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1358"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noncon_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load diagram questions and descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for subject, flexbook in ck12_combined_dataset_cleaned.items():\n",
    "    validator = jsonschema.Draft4Validator(schema)\n",
    "    for error in sorted(validator.iter_errors(flexbook), key=lambda x: x.absolute_path[0]):\n",
    "        print(error.message)\n",
    "        print(list(error.absolute_path)[:4])\n",
    "        print('\\n' * 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
